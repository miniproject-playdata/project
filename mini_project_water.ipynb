{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e075d04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T10:52:39.642838Z",
     "start_time": "2022-07-21T10:52:39.630827Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a411eb99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T11:50:38.438522Z",
     "start_time": "2022-07-21T11:50:38.412992Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 491\n",
       "Hardness             0\n",
       "Solids               0\n",
       "Chloramines          0\n",
       "Sulfate            781\n",
       "Conductivity         0\n",
       "Organic_carbon       0\n",
       "Trihalomethanes    162\n",
       "Turbidity            0\n",
       "Potability           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data  = pd.read_csv('data/water_potability.csv')\n",
    "\n",
    "\n",
    "col = data.columns\n",
    "\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "64c74a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T11:55:11.263555Z",
     "start_time": "2022-07-21T11:55:11.244551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1998\n",
       "1    1278\n",
       "Name: Potability, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Potability.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "576102b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:04.192027Z",
     "start_time": "2022-07-21T12:03:04.156985Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "notpotable  = data[data['Potability']==0]\n",
    "potable = data[data['Potability']==1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "std = 2.2                    ##### 이상치 표준편차로  2.2 넘어가면 모두 NaN 로 반환 >> 3 일시 99퍼  2일시는 몇퍼더라 까먹음 \n",
    "\n",
    "notpotable_scaled = scaler.fit_transform(notpotable)\n",
    "potable_scaled = scaler.fit_transform(potable)\n",
    "\n",
    "potable_scaled = pd.DataFrame(potable_scaled,columns = col)\n",
    "notpotable_scaled = pd.DataFrame(notpotable_scaled,columns = col)\n",
    "\n",
    "\n",
    "potable_outlier =  abs(potable_scaled) >=std\n",
    "notpotable_outlier =  abs(notpotable_scaled) >=std\n",
    "\n",
    "potable_outlier= potable_outlier.replace(True,np.NaN)\n",
    "potable_outlier =potable_outlier.replace(False,0)\n",
    "\n",
    "notpotable_outlier= notpotable_outlier.replace(True,np.NaN)\n",
    "notpotable_outlier =notpotable_outlier.replace(False,0)\n",
    "\n",
    "               \n",
    "potable_scaled = potable_scaled*0\n",
    "potable_outlier = potable_scaled*0+potable_outlier\n",
    "\n",
    "notpotable_scaled = notpotable_scaled*0\n",
    "notpotable_outlier = notpotable_scaled*0+notpotable_outlier\n",
    "\n",
    "\n",
    "\n",
    "potable = potable.reset_index()\n",
    "notpotable = notpotable.reset_index()\n",
    "\n",
    "potable = potable.drop(columns=['index'], axis = 1) + potable_outlier\n",
    "notpotable = notpotable.drop(columns=['index'], axis = 1) +notpotable_outlier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "47d0dd51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:04.736407Z",
     "start_time": "2022-07-21T12:03:04.649992Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Potability         1.000000\n",
       "Solids             0.058368\n",
       "Chloramines        0.054208\n",
       "Sulfate            0.040037\n",
       "Trihalomethanes    0.019232\n",
       "Turbidity         -0.008108\n",
       "Hardness          -0.013994\n",
       "ph                -0.015758\n",
       "Conductivity      -0.025882\n",
       "Organic_carbon    -0.053340\n",
       "Name: Potability, dtype: float64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "  \n",
    "\n",
    "col = data.columns\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "imp.fit(potable)\n",
    "potable_imp =  pd.DataFrame(imp.transform(potable), columns = col)\n",
    "\n",
    "\n",
    "imp.fit(notpotable)\n",
    "notpotable_imp =  pd.DataFrame(imp.transform(notpotable), columns = col)\n",
    "\n",
    "data = pd.concat([notpotable_imp ,potable_imp])\n",
    "data = data.reset_index()\n",
    "data = data.drop(columns=['index'], axis = 1)\n",
    "\n",
    "data = shuffle(data)\n",
    "corr = data.corr()\n",
    "corr[\"Potability\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "410ca10c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:04.963405Z",
     "start_time": "2022-07-21T12:03:04.937973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>7.871961</td>\n",
       "      <td>219.622659</td>\n",
       "      <td>12760.437151</td>\n",
       "      <td>8.076613</td>\n",
       "      <td>360.086657</td>\n",
       "      <td>350.826916</td>\n",
       "      <td>15.698726</td>\n",
       "      <td>84.158080</td>\n",
       "      <td>3.946123</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>8.594416</td>\n",
       "      <td>204.209321</td>\n",
       "      <td>15791.675351</td>\n",
       "      <td>5.912691</td>\n",
       "      <td>322.329604</td>\n",
       "      <td>425.210222</td>\n",
       "      <td>14.216384</td>\n",
       "      <td>54.961285</td>\n",
       "      <td>3.568992</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>6.114332</td>\n",
       "      <td>178.446286</td>\n",
       "      <td>30606.223593</td>\n",
       "      <td>5.568042</td>\n",
       "      <td>325.558867</td>\n",
       "      <td>472.255403</td>\n",
       "      <td>16.711471</td>\n",
       "      <td>66.383570</td>\n",
       "      <td>3.680410</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>7.260904</td>\n",
       "      <td>189.077962</td>\n",
       "      <td>21391.162544</td>\n",
       "      <td>6.576866</td>\n",
       "      <td>356.622222</td>\n",
       "      <td>390.285266</td>\n",
       "      <td>14.391606</td>\n",
       "      <td>81.082456</td>\n",
       "      <td>4.383823</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>6.361667</td>\n",
       "      <td>175.043999</td>\n",
       "      <td>25833.851713</td>\n",
       "      <td>8.243781</td>\n",
       "      <td>333.947107</td>\n",
       "      <td>422.327899</td>\n",
       "      <td>10.558576</td>\n",
       "      <td>70.107693</td>\n",
       "      <td>3.681765</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>6.701941</td>\n",
       "      <td>168.745414</td>\n",
       "      <td>17176.878951</td>\n",
       "      <td>6.390966</td>\n",
       "      <td>330.674729</td>\n",
       "      <td>404.930726</td>\n",
       "      <td>10.827840</td>\n",
       "      <td>52.112707</td>\n",
       "      <td>4.179450</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>6.715140</td>\n",
       "      <td>183.488839</td>\n",
       "      <td>12675.938962</td>\n",
       "      <td>7.028873</td>\n",
       "      <td>319.870584</td>\n",
       "      <td>482.445026</td>\n",
       "      <td>13.309723</td>\n",
       "      <td>66.905142</td>\n",
       "      <td>3.240419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>7.773758</td>\n",
       "      <td>195.928693</td>\n",
       "      <td>21688.616943</td>\n",
       "      <td>6.194910</td>\n",
       "      <td>326.381071</td>\n",
       "      <td>355.831683</td>\n",
       "      <td>14.324552</td>\n",
       "      <td>67.584311</td>\n",
       "      <td>4.040974</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>6.751699</td>\n",
       "      <td>203.400452</td>\n",
       "      <td>26325.817699</td>\n",
       "      <td>8.365470</td>\n",
       "      <td>341.895636</td>\n",
       "      <td>381.440388</td>\n",
       "      <td>14.476459</td>\n",
       "      <td>58.293945</td>\n",
       "      <td>3.756007</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>6.504113</td>\n",
       "      <td>171.722555</td>\n",
       "      <td>20852.764496</td>\n",
       "      <td>7.704990</td>\n",
       "      <td>338.857391</td>\n",
       "      <td>359.460950</td>\n",
       "      <td>13.475273</td>\n",
       "      <td>83.622260</td>\n",
       "      <td>3.931156</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
       "2398  7.871961  219.622659  12760.437151     8.076613  360.086657   \n",
       "779   8.594416  204.209321  15791.675351     5.912691  322.329604   \n",
       "2851  6.114332  178.446286  30606.223593     5.568042  325.558867   \n",
       "1063  7.260904  189.077962  21391.162544     6.576866  356.622222   \n",
       "859   6.361667  175.043999  25833.851713     8.243781  333.947107   \n",
       "...        ...         ...           ...          ...         ...   \n",
       "2812  6.701941  168.745414  17176.878951     6.390966  330.674729   \n",
       "351   6.715140  183.488839  12675.938962     7.028873  319.870584   \n",
       "2740  7.773758  195.928693  21688.616943     6.194910  326.381071   \n",
       "154   6.751699  203.400452  26325.817699     8.365470  341.895636   \n",
       "2634  6.504113  171.722555  20852.764496     7.704990  338.857391   \n",
       "\n",
       "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "2398    350.826916       15.698726        84.158080   3.946123         1.0  \n",
       "779     425.210222       14.216384        54.961285   3.568992         0.0  \n",
       "2851    472.255403       16.711471        66.383570   3.680410         1.0  \n",
       "1063    390.285266       14.391606        81.082456   4.383823         0.0  \n",
       "859     422.327899       10.558576        70.107693   3.681765         0.0  \n",
       "...            ...             ...              ...        ...         ...  \n",
       "2812    404.930726       10.827840        52.112707   4.179450         1.0  \n",
       "351     482.445026       13.309723        66.905142   3.240419         0.0  \n",
       "2740    355.831683       14.324552        67.584311   4.040974         1.0  \n",
       "154     381.440388       14.476459        58.293945   3.756007         0.0  \n",
       "2634    359.460950       13.475273        83.622260   3.931156         1.0  \n",
       "\n",
       "[3276 rows x 10 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fc716640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:05.177932Z",
     "start_time": "2022-07-21T12:03:05.158903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1998\n",
       "1.0    1278\n",
       "Name: Potability, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Potability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "cb78a192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:05.403638Z",
     "start_time": "2022-07-21T12:03:05.383993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 0\n",
       "Hardness           0\n",
       "Solids             0\n",
       "Chloramines        0\n",
       "Sulfate            0\n",
       "Conductivity       0\n",
       "Organic_carbon     0\n",
       "Trihalomethanes    0\n",
       "Turbidity          0\n",
       "Potability         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "1d90dcbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:05.691050Z",
     "start_time": "2022-07-21T12:03:05.681019Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "y = data['Potability']\n",
    "X = data.drop(columns=['Potability'], axis = 1) ### Turbidity 낮은 상관계수 \n",
    "\n",
    "\n",
    "## test_size 확인 \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,stratify=y, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b205c200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:05.994981Z",
     "start_time": "2022-07-21T12:03:05.972999Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "294e1605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:07.214496Z",
     "start_time": "2022-07-21T12:03:06.273018Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961323155216285 0.8245614035087719\n",
      "0.6712328767123288 0.7489082969432315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score,\n",
    "roc_auc_score, average_precision_score, precision_recall_curve, roc_curve,\n",
    "ConfusionMatrixDisplay,  PrecisionRecallDisplay, RocCurveDisplay)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300,\n",
    "                            criterion = 'entropy',\n",
    "                            max_depth=40,\n",
    "                            random_state=10,\n",
    "                            max_features=4,\n",
    "                            min_samples_leaf=5,\n",
    "                            n_jobs=-1\n",
    "                          )\n",
    "\n",
    "\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "rf_pred_train = rf.predict(X_train_scaled)\n",
    "rf_pred_test = rf.predict(X_test_scaled)\n",
    "\n",
    "print(accuracy_score(y_train, rf_pred_train), accuracy_score(y_test, rf_pred_test))\n",
    "print(recall_score(y_test, rf_pred_test), f1_score(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c28dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b5eb8a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:07.229914Z",
     "start_time": "2022-07-21T12:03:07.216495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'딥러닝'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"딥러닝\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b0607a9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:07.292984Z",
     "start_time": "2022-07-21T12:03:07.274972Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.layers import Dropout, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "60cb2946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:07.640856Z",
     "start_time": "2022-07-21T12:03:07.624345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1572, 9), (393, 9), (1311, 9))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=2)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "506389b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:08.004288Z",
     "start_time": "2022-07-21T12:03:07.987799Z"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 300\n",
    "N_BATCHS = 30\n",
    "\n",
    "N_TRAIN = X_train.shape[0]\n",
    "N_VAL = X_val.shape[0]\n",
    "N_TEST = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f6f39aeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:08.324160Z",
     "start_time": "2022-07-21T12:03:08.302157Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1aad0759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:08.673512Z",
     "start_time": "2022-07-21T12:03:08.658976Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train)).shuffle(N_TRAIN).batch(N_BATCHS, drop_remainder=True)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_scaled, y_val)).batch(N_BATCHS)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_scaled, y_test)).batch(N_BATCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f0b79139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:09.157978Z",
     "start_time": "2022-07-21T12:03:09.145969Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_water_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=64, activation='LeakyReLU', input_shape=(9,)))\n",
    "    model.add(layers.Dense(units=32, activation='LeakyReLU'))\n",
    "    model.add(layers.Dense(units=16, activation='LeakyReLU'))\n",
    "    model.add(layers.Dense(units=4, activation='LeakyReLU'))\n",
    "    \n",
    "    model.add(layers.Dense(units=1, activation='sigmoid', name='Output_layer'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a950ff1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:09.626002Z",
     "start_time": "2022-07-21T12:03:09.564035Z"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "N_EPOCHS = 300\n",
    "\n",
    "\n",
    "\n",
    "model = create_water_model()\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=LEARNING_RATE), \n",
    "              loss='mean_squared_logarithmic_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6c9c625d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:37.646954Z",
     "start_time": "2022-07-21T12:03:10.886006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.4596 - val_loss: 0.1356 - val_accuracy: 0.4682\n",
      "Epoch 2/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.5333 - val_loss: 0.1323 - val_accuracy: 0.4936\n",
      "Epoch 3/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.5801 - val_loss: 0.1295 - val_accuracy: 0.5649\n",
      "Epoch 4/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.6135 - val_loss: 0.1272 - val_accuracy: 0.5878\n",
      "Epoch 5/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.6115 - val_loss: 0.1253 - val_accuracy: 0.6132\n",
      "Epoch 6/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.6173 - val_loss: 0.1236 - val_accuracy: 0.6209\n",
      "Epoch 7/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.6128 - val_loss: 0.1223 - val_accuracy: 0.6132\n",
      "Epoch 8/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.6192 - val_loss: 0.1211 - val_accuracy: 0.6158\n",
      "Epoch 9/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.6205 - val_loss: 0.1200 - val_accuracy: 0.6107\n",
      "Epoch 10/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.6135 - val_loss: 0.1191 - val_accuracy: 0.6081\n",
      "Epoch 11/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.6109 - val_loss: 0.1184 - val_accuracy: 0.6107\n",
      "Epoch 12/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.6128 - val_loss: 0.1177 - val_accuracy: 0.6107\n",
      "Epoch 13/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.6115 - val_loss: 0.1172 - val_accuracy: 0.6107\n",
      "Epoch 14/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.6103 - val_loss: 0.1167 - val_accuracy: 0.6107\n",
      "Epoch 15/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.6122 - val_loss: 0.1163 - val_accuracy: 0.6107\n",
      "Epoch 16/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.6128 - val_loss: 0.1159 - val_accuracy: 0.6107\n",
      "Epoch 17/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.6135 - val_loss: 0.1156 - val_accuracy: 0.6107\n",
      "Epoch 18/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.6115 - val_loss: 0.1153 - val_accuracy: 0.6107\n",
      "Epoch 19/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.6115 - val_loss: 0.1150 - val_accuracy: 0.6107\n",
      "Epoch 20/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.6083 - val_loss: 0.1148 - val_accuracy: 0.6107\n",
      "Epoch 21/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.6096 - val_loss: 0.1146 - val_accuracy: 0.6107\n",
      "Epoch 22/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.6103 - val_loss: 0.1144 - val_accuracy: 0.6107\n",
      "Epoch 23/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.6128 - val_loss: 0.1142 - val_accuracy: 0.6107\n",
      "Epoch 24/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.6103 - val_loss: 0.1140 - val_accuracy: 0.6107\n",
      "Epoch 25/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.6115 - val_loss: 0.1138 - val_accuracy: 0.6107\n",
      "Epoch 26/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.6103 - val_loss: 0.1137 - val_accuracy: 0.6107\n",
      "Epoch 27/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.6122 - val_loss: 0.1135 - val_accuracy: 0.6107\n",
      "Epoch 28/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.6154 - val_loss: 0.1133 - val_accuracy: 0.6107\n",
      "Epoch 29/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.6154 - val_loss: 0.1132 - val_accuracy: 0.6107\n",
      "Epoch 30/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.6147 - val_loss: 0.1130 - val_accuracy: 0.6107\n",
      "Epoch 31/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.6122 - val_loss: 0.1129 - val_accuracy: 0.6107\n",
      "Epoch 32/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.6128 - val_loss: 0.1127 - val_accuracy: 0.6107\n",
      "Epoch 33/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.6154 - val_loss: 0.1126 - val_accuracy: 0.6132\n",
      "Epoch 34/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.6160 - val_loss: 0.1124 - val_accuracy: 0.6132\n",
      "Epoch 35/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.6154 - val_loss: 0.1123 - val_accuracy: 0.6132\n",
      "Epoch 36/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.6167 - val_loss: 0.1122 - val_accuracy: 0.6132\n",
      "Epoch 37/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.6199 - val_loss: 0.1120 - val_accuracy: 0.6107\n",
      "Epoch 38/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.6167 - val_loss: 0.1119 - val_accuracy: 0.6107\n",
      "Epoch 39/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.6167 - val_loss: 0.1117 - val_accuracy: 0.6107\n",
      "Epoch 40/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.6173 - val_loss: 0.1116 - val_accuracy: 0.6107\n",
      "Epoch 41/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.6205 - val_loss: 0.1115 - val_accuracy: 0.6107\n",
      "Epoch 42/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.6231 - val_loss: 0.1113 - val_accuracy: 0.6132\n",
      "Epoch 43/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.6205 - val_loss: 0.1112 - val_accuracy: 0.6158\n",
      "Epoch 44/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.6224 - val_loss: 0.1110 - val_accuracy: 0.6158\n",
      "Epoch 45/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.6237 - val_loss: 0.1109 - val_accuracy: 0.6183\n",
      "Epoch 46/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.6256 - val_loss: 0.1107 - val_accuracy: 0.6183\n",
      "Epoch 47/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.6276 - val_loss: 0.1106 - val_accuracy: 0.6158\n",
      "Epoch 48/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.6282 - val_loss: 0.1104 - val_accuracy: 0.6183\n",
      "Epoch 49/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.6288 - val_loss: 0.1103 - val_accuracy: 0.6209\n",
      "Epoch 50/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.6282 - val_loss: 0.1101 - val_accuracy: 0.6234\n",
      "Epoch 51/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.6301 - val_loss: 0.1099 - val_accuracy: 0.6234\n",
      "Epoch 52/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.6333 - val_loss: 0.1098 - val_accuracy: 0.6234\n",
      "Epoch 53/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.6321 - val_loss: 0.1096 - val_accuracy: 0.6234\n",
      "Epoch 54/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.6346 - val_loss: 0.1094 - val_accuracy: 0.6234\n",
      "Epoch 55/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.6321 - val_loss: 0.1092 - val_accuracy: 0.6260\n",
      "Epoch 56/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.6340 - val_loss: 0.1091 - val_accuracy: 0.6260\n",
      "Epoch 57/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.6340 - val_loss: 0.1089 - val_accuracy: 0.6285\n",
      "Epoch 58/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.6340 - val_loss: 0.1087 - val_accuracy: 0.6260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1038 - accuracy: 0.6346 - val_loss: 0.1085 - val_accuracy: 0.6285\n",
      "Epoch 60/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.6346 - val_loss: 0.1083 - val_accuracy: 0.6285\n",
      "Epoch 61/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.6378 - val_loss: 0.1081 - val_accuracy: 0.6285\n",
      "Epoch 62/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.6378 - val_loss: 0.1079 - val_accuracy: 0.6285\n",
      "Epoch 63/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.6378 - val_loss: 0.1077 - val_accuracy: 0.6310\n",
      "Epoch 64/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.6365 - val_loss: 0.1075 - val_accuracy: 0.6285\n",
      "Epoch 65/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.6359 - val_loss: 0.1072 - val_accuracy: 0.6285\n",
      "Epoch 66/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.6359 - val_loss: 0.1070 - val_accuracy: 0.6310\n",
      "Epoch 67/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.6365 - val_loss: 0.1068 - val_accuracy: 0.6361\n",
      "Epoch 68/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.6365 - val_loss: 0.1065 - val_accuracy: 0.6361\n",
      "Epoch 69/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.6372 - val_loss: 0.1063 - val_accuracy: 0.6361\n",
      "Epoch 70/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.6378 - val_loss: 0.1061 - val_accuracy: 0.6361\n",
      "Epoch 71/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.6391 - val_loss: 0.1058 - val_accuracy: 0.6361\n",
      "Epoch 72/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.6397 - val_loss: 0.1055 - val_accuracy: 0.6387\n",
      "Epoch 73/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.6391 - val_loss: 0.1053 - val_accuracy: 0.6412\n",
      "Epoch 74/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.6417 - val_loss: 0.1050 - val_accuracy: 0.6412\n",
      "Epoch 75/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0995 - accuracy: 0.6436 - val_loss: 0.1048 - val_accuracy: 0.6412\n",
      "Epoch 76/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.6423 - val_loss: 0.1045 - val_accuracy: 0.6412\n",
      "Epoch 77/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.6455 - val_loss: 0.1042 - val_accuracy: 0.6438\n",
      "Epoch 78/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.6449 - val_loss: 0.1039 - val_accuracy: 0.6438\n",
      "Epoch 79/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.6494 - val_loss: 0.1036 - val_accuracy: 0.6438\n",
      "Epoch 80/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.6487 - val_loss: 0.1033 - val_accuracy: 0.6438\n",
      "Epoch 81/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.6519 - val_loss: 0.1030 - val_accuracy: 0.6438\n",
      "Epoch 82/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.6526 - val_loss: 0.1027 - val_accuracy: 0.6438\n",
      "Epoch 83/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.6551 - val_loss: 0.1024 - val_accuracy: 0.6438\n",
      "Epoch 84/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.6571 - val_loss: 0.1021 - val_accuracy: 0.6463\n",
      "Epoch 85/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.6609 - val_loss: 0.1017 - val_accuracy: 0.6489\n",
      "Epoch 86/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.6615 - val_loss: 0.1014 - val_accuracy: 0.6489\n",
      "Epoch 87/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.6679 - val_loss: 0.1011 - val_accuracy: 0.6489\n",
      "Epoch 88/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.6641 - val_loss: 0.1007 - val_accuracy: 0.6489\n",
      "Epoch 89/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.6718 - val_loss: 0.1004 - val_accuracy: 0.6489\n",
      "Epoch 90/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.6724 - val_loss: 0.1001 - val_accuracy: 0.6489\n",
      "Epoch 91/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.6756 - val_loss: 0.0997 - val_accuracy: 0.6514\n",
      "Epoch 92/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.6795 - val_loss: 0.0994 - val_accuracy: 0.6489\n",
      "Epoch 93/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.6788 - val_loss: 0.0991 - val_accuracy: 0.6590\n",
      "Epoch 94/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.6853 - val_loss: 0.0988 - val_accuracy: 0.6565\n",
      "Epoch 95/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.6833 - val_loss: 0.0985 - val_accuracy: 0.6641\n",
      "Epoch 96/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.6859 - val_loss: 0.0982 - val_accuracy: 0.6641\n",
      "Epoch 97/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.6904 - val_loss: 0.0979 - val_accuracy: 0.6692\n",
      "Epoch 98/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.6936 - val_loss: 0.0976 - val_accuracy: 0.6692\n",
      "Epoch 99/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.6949 - val_loss: 0.0973 - val_accuracy: 0.6692\n",
      "Epoch 100/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.7006 - val_loss: 0.0970 - val_accuracy: 0.6718\n",
      "Epoch 101/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.7006 - val_loss: 0.0967 - val_accuracy: 0.6718\n",
      "Epoch 102/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.7045 - val_loss: 0.0964 - val_accuracy: 0.6743\n",
      "Epoch 103/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.7090 - val_loss: 0.0961 - val_accuracy: 0.6743\n",
      "Epoch 104/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.7083 - val_loss: 0.0959 - val_accuracy: 0.6794\n",
      "Epoch 105/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.7103 - val_loss: 0.0956 - val_accuracy: 0.6819\n",
      "Epoch 106/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.7109 - val_loss: 0.0953 - val_accuracy: 0.6845\n",
      "Epoch 107/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.7167 - val_loss: 0.0951 - val_accuracy: 0.6845\n",
      "Epoch 108/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0880 - accuracy: 0.7167 - val_loss: 0.0948 - val_accuracy: 0.6921\n",
      "Epoch 109/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.7212 - val_loss: 0.0946 - val_accuracy: 0.6947\n",
      "Epoch 110/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.7218 - val_loss: 0.0943 - val_accuracy: 0.6947\n",
      "Epoch 111/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.7256 - val_loss: 0.0941 - val_accuracy: 0.6947\n",
      "Epoch 112/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.7314 - val_loss: 0.0939 - val_accuracy: 0.6947\n",
      "Epoch 113/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.7282 - val_loss: 0.0936 - val_accuracy: 0.6997\n",
      "Epoch 114/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.7282 - val_loss: 0.0934 - val_accuracy: 0.7023\n",
      "Epoch 115/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.7288 - val_loss: 0.0931 - val_accuracy: 0.7048\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.7321 - val_loss: 0.0929 - val_accuracy: 0.7048\n",
      "Epoch 117/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.7372 - val_loss: 0.0927 - val_accuracy: 0.7125\n",
      "Epoch 118/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.7385 - val_loss: 0.0925 - val_accuracy: 0.7150\n",
      "Epoch 119/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.7378 - val_loss: 0.0923 - val_accuracy: 0.7150\n",
      "Epoch 120/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.7410 - val_loss: 0.0921 - val_accuracy: 0.7150\n",
      "Epoch 121/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.7417 - val_loss: 0.0919 - val_accuracy: 0.7150\n",
      "Epoch 122/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.7429 - val_loss: 0.0917 - val_accuracy: 0.7150\n",
      "Epoch 123/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.7455 - val_loss: 0.0915 - val_accuracy: 0.7150\n",
      "Epoch 124/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.7442 - val_loss: 0.0913 - val_accuracy: 0.7176\n",
      "Epoch 125/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.7532 - val_loss: 0.0911 - val_accuracy: 0.7176\n",
      "Epoch 126/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.7519 - val_loss: 0.0910 - val_accuracy: 0.7176\n",
      "Epoch 127/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.7506 - val_loss: 0.0908 - val_accuracy: 0.7176\n",
      "Epoch 128/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.7564 - val_loss: 0.0906 - val_accuracy: 0.7176\n",
      "Epoch 129/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.7558 - val_loss: 0.0905 - val_accuracy: 0.7176\n",
      "Epoch 130/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.7538 - val_loss: 0.0904 - val_accuracy: 0.7176\n",
      "Epoch 131/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.7571 - val_loss: 0.0902 - val_accuracy: 0.7176\n",
      "Epoch 132/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.7571 - val_loss: 0.0901 - val_accuracy: 0.7150\n",
      "Epoch 133/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.7603 - val_loss: 0.0899 - val_accuracy: 0.7176\n",
      "Epoch 134/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.7609 - val_loss: 0.0898 - val_accuracy: 0.7201\n",
      "Epoch 135/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.7603 - val_loss: 0.0897 - val_accuracy: 0.7201\n",
      "Epoch 136/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.7583 - val_loss: 0.0896 - val_accuracy: 0.7201\n",
      "Epoch 137/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.7583 - val_loss: 0.0895 - val_accuracy: 0.7226\n",
      "Epoch 138/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.7590 - val_loss: 0.0894 - val_accuracy: 0.7252\n",
      "Epoch 139/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.7635 - val_loss: 0.0893 - val_accuracy: 0.7328\n",
      "Epoch 140/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.7622 - val_loss: 0.0891 - val_accuracy: 0.7328\n",
      "Epoch 141/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.7628 - val_loss: 0.0890 - val_accuracy: 0.7303\n",
      "Epoch 142/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.7647 - val_loss: 0.0890 - val_accuracy: 0.7328\n",
      "Epoch 143/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.7628 - val_loss: 0.0889 - val_accuracy: 0.7328\n",
      "Epoch 144/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.7628 - val_loss: 0.0888 - val_accuracy: 0.7354\n",
      "Epoch 145/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.7628 - val_loss: 0.0887 - val_accuracy: 0.7354\n",
      "Epoch 146/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.7660 - val_loss: 0.0886 - val_accuracy: 0.7379\n",
      "Epoch 147/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.7660 - val_loss: 0.0886 - val_accuracy: 0.7354\n",
      "Epoch 148/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.7635 - val_loss: 0.0885 - val_accuracy: 0.7379\n",
      "Epoch 149/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0800 - accuracy: 0.7641 - val_loss: 0.0884 - val_accuracy: 0.7379\n",
      "Epoch 150/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.7641 - val_loss: 0.0883 - val_accuracy: 0.7354\n",
      "Epoch 151/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.7647 - val_loss: 0.0883 - val_accuracy: 0.7354\n",
      "Epoch 152/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.7647 - val_loss: 0.0882 - val_accuracy: 0.7379\n",
      "Epoch 153/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.7654 - val_loss: 0.0882 - val_accuracy: 0.7328\n",
      "Epoch 154/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.7705 - val_loss: 0.0881 - val_accuracy: 0.7354\n",
      "Epoch 155/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.7692 - val_loss: 0.0881 - val_accuracy: 0.7354\n",
      "Epoch 156/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.7660 - val_loss: 0.0880 - val_accuracy: 0.7354\n",
      "Epoch 157/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.7699 - val_loss: 0.0880 - val_accuracy: 0.7354\n",
      "Epoch 158/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.7686 - val_loss: 0.0879 - val_accuracy: 0.7354\n",
      "Epoch 159/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.7679 - val_loss: 0.0879 - val_accuracy: 0.7354\n",
      "Epoch 160/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.7699 - val_loss: 0.0878 - val_accuracy: 0.7303\n",
      "Epoch 161/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.7712 - val_loss: 0.0878 - val_accuracy: 0.7328\n",
      "Epoch 162/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.7731 - val_loss: 0.0878 - val_accuracy: 0.7354\n",
      "Epoch 163/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.7699 - val_loss: 0.0877 - val_accuracy: 0.7354\n",
      "Epoch 164/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0782 - accuracy: 0.7699 - val_loss: 0.0877 - val_accuracy: 0.7354\n",
      "Epoch 165/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.7724 - val_loss: 0.0876 - val_accuracy: 0.7328\n",
      "Epoch 166/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.7712 - val_loss: 0.0876 - val_accuracy: 0.7354\n",
      "Epoch 167/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.7718 - val_loss: 0.0876 - val_accuracy: 0.7328\n",
      "Epoch 168/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.7731 - val_loss: 0.0875 - val_accuracy: 0.7303\n",
      "Epoch 169/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.7718 - val_loss: 0.0875 - val_accuracy: 0.7303\n",
      "Epoch 170/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.7718 - val_loss: 0.0875 - val_accuracy: 0.7354\n",
      "Epoch 171/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.7750 - val_loss: 0.0875 - val_accuracy: 0.7354\n",
      "Epoch 172/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.7756 - val_loss: 0.0875 - val_accuracy: 0.7354\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.7750 - val_loss: 0.0874 - val_accuracy: 0.7303\n",
      "Epoch 174/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0771 - accuracy: 0.7750 - val_loss: 0.0874 - val_accuracy: 0.7328\n",
      "Epoch 175/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.7756 - val_loss: 0.0873 - val_accuracy: 0.7354\n",
      "Epoch 176/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0771 - accuracy: 0.7763 - val_loss: 0.0873 - val_accuracy: 0.7354\n",
      "Epoch 177/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.7737 - val_loss: 0.0873 - val_accuracy: 0.7354\n",
      "Epoch 178/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.7756 - val_loss: 0.0873 - val_accuracy: 0.7354\n",
      "Epoch 179/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.7769 - val_loss: 0.0872 - val_accuracy: 0.7379\n",
      "Epoch 180/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.7769 - val_loss: 0.0872 - val_accuracy: 0.7379\n",
      "Epoch 181/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.7756 - val_loss: 0.0872 - val_accuracy: 0.7379\n",
      "Epoch 182/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.7795 - val_loss: 0.0872 - val_accuracy: 0.7379\n",
      "Epoch 183/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.7795 - val_loss: 0.0872 - val_accuracy: 0.7379\n",
      "Epoch 184/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.7763 - val_loss: 0.0872 - val_accuracy: 0.7379\n",
      "Epoch 185/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.7782 - val_loss: 0.0871 - val_accuracy: 0.7354\n",
      "Epoch 186/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.7782 - val_loss: 0.0871 - val_accuracy: 0.7405\n",
      "Epoch 187/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.7769 - val_loss: 0.0872 - val_accuracy: 0.7405\n",
      "Epoch 188/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.7782 - val_loss: 0.0872 - val_accuracy: 0.7430\n",
      "Epoch 189/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.7769 - val_loss: 0.0872 - val_accuracy: 0.7430\n",
      "Epoch 190/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.7776 - val_loss: 0.0872 - val_accuracy: 0.7430\n",
      "Epoch 191/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.7808 - val_loss: 0.0871 - val_accuracy: 0.7430\n",
      "Epoch 192/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.7795 - val_loss: 0.0871 - val_accuracy: 0.7430\n",
      "Epoch 193/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.7788 - val_loss: 0.0871 - val_accuracy: 0.7430\n",
      "Epoch 194/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.7788 - val_loss: 0.0871 - val_accuracy: 0.7455\n",
      "Epoch 195/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.7801 - val_loss: 0.0871 - val_accuracy: 0.7455\n",
      "Epoch 196/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.7801 - val_loss: 0.0871 - val_accuracy: 0.7455\n",
      "Epoch 197/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.7801 - val_loss: 0.0871 - val_accuracy: 0.7481\n",
      "Epoch 198/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.7821 - val_loss: 0.0871 - val_accuracy: 0.7506\n",
      "Epoch 199/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.7788 - val_loss: 0.0871 - val_accuracy: 0.7481\n",
      "Epoch 200/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.7814 - val_loss: 0.0871 - val_accuracy: 0.7506\n",
      "Epoch 201/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.7788 - val_loss: 0.0871 - val_accuracy: 0.7481\n",
      "Epoch 202/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.7801 - val_loss: 0.0871 - val_accuracy: 0.7506\n",
      "Epoch 203/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.7814 - val_loss: 0.0871 - val_accuracy: 0.7481\n",
      "Epoch 204/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.7808 - val_loss: 0.0871 - val_accuracy: 0.7506\n",
      "Epoch 205/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.7821 - val_loss: 0.0871 - val_accuracy: 0.7506\n",
      "Epoch 206/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.7833 - val_loss: 0.0870 - val_accuracy: 0.7506\n",
      "Epoch 207/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.7801 - val_loss: 0.0870 - val_accuracy: 0.7532\n",
      "Epoch 208/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.7846 - val_loss: 0.0871 - val_accuracy: 0.7532\n",
      "Epoch 209/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.7821 - val_loss: 0.0871 - val_accuracy: 0.7532\n",
      "Epoch 210/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.7801 - val_loss: 0.0871 - val_accuracy: 0.7532\n",
      "Epoch 211/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.7808 - val_loss: 0.0871 - val_accuracy: 0.7506\n",
      "Epoch 212/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.7833 - val_loss: 0.0871 - val_accuracy: 0.7506\n",
      "Epoch 213/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.7853 - val_loss: 0.0870 - val_accuracy: 0.7532\n",
      "Epoch 214/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.7827 - val_loss: 0.0870 - val_accuracy: 0.7532\n",
      "Epoch 215/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.7821 - val_loss: 0.0871 - val_accuracy: 0.7506\n",
      "Epoch 216/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.7853 - val_loss: 0.0871 - val_accuracy: 0.7532\n",
      "Epoch 217/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.7859 - val_loss: 0.0870 - val_accuracy: 0.7532\n",
      "Epoch 218/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.7827 - val_loss: 0.0870 - val_accuracy: 0.7506\n",
      "Epoch 219/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.7821 - val_loss: 0.0871 - val_accuracy: 0.7532\n",
      "Epoch 220/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.7827 - val_loss: 0.0871 - val_accuracy: 0.7557\n",
      "Epoch 221/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.7846 - val_loss: 0.0871 - val_accuracy: 0.7557\n",
      "Epoch 222/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.7853 - val_loss: 0.0871 - val_accuracy: 0.7532\n",
      "Epoch 223/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.7853 - val_loss: 0.0871 - val_accuracy: 0.7506\n",
      "Epoch 224/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.7846 - val_loss: 0.0872 - val_accuracy: 0.7532\n",
      "Epoch 225/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.7840 - val_loss: 0.0871 - val_accuracy: 0.7532\n",
      "Epoch 226/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.7827 - val_loss: 0.0872 - val_accuracy: 0.7557\n",
      "Epoch 227/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.7853 - val_loss: 0.0872 - val_accuracy: 0.7532\n",
      "Epoch 228/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.7840 - val_loss: 0.0872 - val_accuracy: 0.7557\n",
      "Epoch 229/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.7853 - val_loss: 0.0872 - val_accuracy: 0.7532\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.7846 - val_loss: 0.0872 - val_accuracy: 0.7557\n",
      "Epoch 231/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.7865 - val_loss: 0.0872 - val_accuracy: 0.7557\n",
      "Epoch 232/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.7846 - val_loss: 0.0872 - val_accuracy: 0.7583\n",
      "Epoch 233/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.7846 - val_loss: 0.0872 - val_accuracy: 0.7583\n",
      "Epoch 234/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.7846 - val_loss: 0.0872 - val_accuracy: 0.7583\n",
      "Epoch 235/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.7859 - val_loss: 0.0872 - val_accuracy: 0.7608\n",
      "Epoch 236/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.7885 - val_loss: 0.0871 - val_accuracy: 0.7583\n",
      "Epoch 237/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.7859 - val_loss: 0.0871 - val_accuracy: 0.7608\n",
      "Epoch 238/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.7885 - val_loss: 0.0871 - val_accuracy: 0.7557\n",
      "Epoch 239/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.7885 - val_loss: 0.0871 - val_accuracy: 0.7583\n",
      "Epoch 240/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.7859 - val_loss: 0.0872 - val_accuracy: 0.7583\n",
      "Epoch 241/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.7878 - val_loss: 0.0873 - val_accuracy: 0.7608\n",
      "Epoch 242/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.7897 - val_loss: 0.0872 - val_accuracy: 0.7634\n",
      "Epoch 243/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.7885 - val_loss: 0.0872 - val_accuracy: 0.7634\n",
      "Epoch 244/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.7897 - val_loss: 0.0873 - val_accuracy: 0.7634\n",
      "Epoch 245/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.7878 - val_loss: 0.0872 - val_accuracy: 0.7634\n",
      "Epoch 246/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.7917 - val_loss: 0.0872 - val_accuracy: 0.7608\n",
      "Epoch 247/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.7878 - val_loss: 0.0872 - val_accuracy: 0.7583\n",
      "Epoch 248/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.7885 - val_loss: 0.0872 - val_accuracy: 0.7608\n",
      "Epoch 249/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.7846 - val_loss: 0.0873 - val_accuracy: 0.7634\n",
      "Epoch 250/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.7897 - val_loss: 0.0873 - val_accuracy: 0.7634\n",
      "Epoch 251/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.7897 - val_loss: 0.0873 - val_accuracy: 0.7634\n",
      "Epoch 252/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.7904 - val_loss: 0.0874 - val_accuracy: 0.7608\n",
      "Epoch 253/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.7897 - val_loss: 0.0873 - val_accuracy: 0.7608\n",
      "Epoch 254/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.7910 - val_loss: 0.0874 - val_accuracy: 0.7608\n",
      "Epoch 255/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.7910 - val_loss: 0.0874 - val_accuracy: 0.7608\n",
      "Epoch 256/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.7904 - val_loss: 0.0874 - val_accuracy: 0.7608\n",
      "Epoch 257/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.7923 - val_loss: 0.0874 - val_accuracy: 0.7608\n",
      "Epoch 258/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.7936 - val_loss: 0.0874 - val_accuracy: 0.7608\n",
      "Epoch 259/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.7897 - val_loss: 0.0874 - val_accuracy: 0.7608\n",
      "Epoch 260/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 0.7897 - val_loss: 0.0874 - val_accuracy: 0.7583\n",
      "Epoch 261/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.7942 - val_loss: 0.0874 - val_accuracy: 0.7532\n",
      "Epoch 262/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.7910 - val_loss: 0.0874 - val_accuracy: 0.7583\n",
      "Epoch 263/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.7910 - val_loss: 0.0875 - val_accuracy: 0.7608\n",
      "Epoch 264/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.7942 - val_loss: 0.0875 - val_accuracy: 0.7608\n",
      "Epoch 265/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.7955 - val_loss: 0.0874 - val_accuracy: 0.7557\n",
      "Epoch 266/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.7904 - val_loss: 0.0875 - val_accuracy: 0.7608\n",
      "Epoch 267/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.7955 - val_loss: 0.0874 - val_accuracy: 0.7532\n",
      "Epoch 268/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.7929 - val_loss: 0.0875 - val_accuracy: 0.7608\n",
      "Epoch 269/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.7955 - val_loss: 0.0874 - val_accuracy: 0.7583\n",
      "Epoch 270/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.7942 - val_loss: 0.0874 - val_accuracy: 0.7557\n",
      "Epoch 271/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.7936 - val_loss: 0.0876 - val_accuracy: 0.7608\n",
      "Epoch 272/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0716 - accuracy: 0.7955 - val_loss: 0.0875 - val_accuracy: 0.7583\n",
      "Epoch 273/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.7968 - val_loss: 0.0875 - val_accuracy: 0.7583\n",
      "Epoch 274/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.7955 - val_loss: 0.0875 - val_accuracy: 0.7557\n",
      "Epoch 275/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.7949 - val_loss: 0.0876 - val_accuracy: 0.7583\n",
      "Epoch 276/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.7968 - val_loss: 0.0877 - val_accuracy: 0.7608\n",
      "Epoch 277/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.7962 - val_loss: 0.0877 - val_accuracy: 0.7608\n",
      "Epoch 278/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.7955 - val_loss: 0.0877 - val_accuracy: 0.7583\n",
      "Epoch 279/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.7968 - val_loss: 0.0877 - val_accuracy: 0.7583\n",
      "Epoch 280/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.7955 - val_loss: 0.0876 - val_accuracy: 0.7608\n",
      "Epoch 281/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.7955 - val_loss: 0.0877 - val_accuracy: 0.7583\n",
      "Epoch 282/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.7974 - val_loss: 0.0877 - val_accuracy: 0.7557\n",
      "Epoch 283/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.7962 - val_loss: 0.0877 - val_accuracy: 0.7557\n",
      "Epoch 284/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.7949 - val_loss: 0.0877 - val_accuracy: 0.7583\n",
      "Epoch 285/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.7955 - val_loss: 0.0877 - val_accuracy: 0.7583\n",
      "Epoch 286/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.7974 - val_loss: 0.0877 - val_accuracy: 0.7608\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.7955 - val_loss: 0.0877 - val_accuracy: 0.7583\n",
      "Epoch 288/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.7968 - val_loss: 0.0877 - val_accuracy: 0.7557\n",
      "Epoch 289/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.7962 - val_loss: 0.0877 - val_accuracy: 0.7583\n",
      "Epoch 290/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.7962 - val_loss: 0.0878 - val_accuracy: 0.7583\n",
      "Epoch 291/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.7974 - val_loss: 0.0878 - val_accuracy: 0.7532\n",
      "Epoch 292/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.7962 - val_loss: 0.0877 - val_accuracy: 0.7583\n",
      "Epoch 293/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.7974 - val_loss: 0.0878 - val_accuracy: 0.7608\n",
      "Epoch 294/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.7962 - val_loss: 0.0878 - val_accuracy: 0.7583\n",
      "Epoch 295/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.8000 - val_loss: 0.0878 - val_accuracy: 0.7608\n",
      "Epoch 296/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.7981 - val_loss: 0.0878 - val_accuracy: 0.7532\n",
      "Epoch 297/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.7962 - val_loss: 0.0878 - val_accuracy: 0.7532\n",
      "Epoch 298/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.7987 - val_loss: 0.0879 - val_accuracy: 0.7557\n",
      "Epoch 299/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.7942 - val_loss: 0.0879 - val_accuracy: 0.7557\n",
      "Epoch 300/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.8000 - val_loss: 0.0879 - val_accuracy: 0.7557\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_dataset, epochs=N_EPOCHS, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "300b8d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:41.303370Z",
     "start_time": "2022-07-21T12:03:41.178982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(range(1, N_EPOCHS+1), hist.history['loss'], label='Train Loss')\n",
    "plt.plot(range(1, N_EPOCHS+1), hist.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss', fontsize=20)\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e1a06597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T12:03:44.095841Z",
     "start_time": "2022-07-21T12:03:44.016981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.7712\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09992aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

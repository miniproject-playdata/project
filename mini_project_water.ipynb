{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1540,
   "id": "1e075d04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:06:39.477189Z",
     "start_time": "2022-07-21T06:06:39.440710Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1540]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaBoostClassifier\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomizedSearchCV, GridSearchCV\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1541,
   "id": "a411eb99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:06:40.267170Z",
     "start_time": "2022-07-21T06:06:40.245651Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data  = pd.read_csv('data/water_potability.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1542,
   "id": "64c74a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:06:40.403627Z",
     "start_time": "2022-07-21T06:06:40.396634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1998\n",
       "1    1278\n",
       "Name: Potability, dtype: int64"
      ]
     },
     "execution_count": 1542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Potability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1543,
   "id": "47d0dd51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:06:40.648651Z",
     "start_time": "2022-07-21T06:06:40.533136Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Potability         1.000000\n",
       "Solids             0.033743\n",
       "Chloramines        0.023779\n",
       "Trihalomethanes    0.007191\n",
       "Turbidity          0.001581\n",
       "ph                -0.006596\n",
       "Conductivity      -0.008128\n",
       "Hardness          -0.013837\n",
       "Sulfate           -0.021491\n",
       "Organic_carbon    -0.030001\n",
       "Name: Potability, dtype: float64"
      ]
     },
     "execution_count": 1543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "notpotable  = data[data['Potability']==0]\n",
    "potable = data[data['Potability']==1]  \n",
    "\n",
    "col = data.columns\n",
    "\n",
    "\n",
    "\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp.fit(potable)\n",
    "potable_imp =  pd.DataFrame(imp.transform(potable), columns = col)\n",
    "\n",
    "\n",
    "imp.fit(notpotable)\n",
    "notpotable_imp =  pd.DataFrame(imp.transform(notpotable), columns = col)\n",
    "\n",
    "data = pd.concat([notpotable_imp ,potable_imp])\n",
    "\n",
    "data = shuffle(data)\n",
    "corr = data.corr()\n",
    "corr[\"Potability\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1544,
   "id": "fc716640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:06:40.680649Z",
     "start_time": "2022-07-21T06:06:40.667639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1998\n",
       "1.0    1278\n",
       "Name: Potability, dtype: int64"
      ]
     },
     "execution_count": 1544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Potability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83bce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T05:49:56.356566Z",
     "start_time": "2022-07-21T05:49:56.327528Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "id": "1d90dcbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:06:40.956649Z",
     "start_time": "2022-07-21T06:06:40.932645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>9.228582</td>\n",
       "      <td>180.944697</td>\n",
       "      <td>10345.399315</td>\n",
       "      <td>6.056989</td>\n",
       "      <td>349.557042</td>\n",
       "      <td>397.043130</td>\n",
       "      <td>18.215464</td>\n",
       "      <td>53.976734</td>\n",
       "      <td>3.839185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>9.011589</td>\n",
       "      <td>228.919519</td>\n",
       "      <td>25208.151842</td>\n",
       "      <td>6.767010</td>\n",
       "      <td>339.290404</td>\n",
       "      <td>380.145205</td>\n",
       "      <td>15.518323</td>\n",
       "      <td>66.142731</td>\n",
       "      <td>2.897293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>7.230845</td>\n",
       "      <td>177.574803</td>\n",
       "      <td>17864.689386</td>\n",
       "      <td>5.818229</td>\n",
       "      <td>343.593332</td>\n",
       "      <td>367.689992</td>\n",
       "      <td>19.912950</td>\n",
       "      <td>59.303053</td>\n",
       "      <td>5.622018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>6.968651</td>\n",
       "      <td>193.926180</td>\n",
       "      <td>14936.503971</td>\n",
       "      <td>7.203401</td>\n",
       "      <td>309.447432</td>\n",
       "      <td>447.450108</td>\n",
       "      <td>12.180626</td>\n",
       "      <td>66.622860</td>\n",
       "      <td>4.297914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.072983</td>\n",
       "      <td>150.174923</td>\n",
       "      <td>27331.361962</td>\n",
       "      <td>6.838223</td>\n",
       "      <td>299.415781</td>\n",
       "      <td>379.761835</td>\n",
       "      <td>19.370807</td>\n",
       "      <td>76.509996</td>\n",
       "      <td>4.413974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>9.597192</td>\n",
       "      <td>167.088976</td>\n",
       "      <td>21153.322827</td>\n",
       "      <td>7.944469</td>\n",
       "      <td>346.075016</td>\n",
       "      <td>335.197608</td>\n",
       "      <td>14.347676</td>\n",
       "      <td>50.642447</td>\n",
       "      <td>5.145153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>5.895949</td>\n",
       "      <td>187.153617</td>\n",
       "      <td>37118.255436</td>\n",
       "      <td>4.600730</td>\n",
       "      <td>253.158469</td>\n",
       "      <td>531.169101</td>\n",
       "      <td>11.410184</td>\n",
       "      <td>77.286551</td>\n",
       "      <td>3.659653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>7.156956</td>\n",
       "      <td>167.104430</td>\n",
       "      <td>30362.683948</td>\n",
       "      <td>9.990332</td>\n",
       "      <td>362.261636</td>\n",
       "      <td>432.030710</td>\n",
       "      <td>9.971476</td>\n",
       "      <td>94.984101</td>\n",
       "      <td>3.346057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>6.698154</td>\n",
       "      <td>198.286268</td>\n",
       "      <td>34675.862845</td>\n",
       "      <td>6.263602</td>\n",
       "      <td>360.232834</td>\n",
       "      <td>430.935009</td>\n",
       "      <td>12.176678</td>\n",
       "      <td>65.747444</td>\n",
       "      <td>3.758180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>6.903074</td>\n",
       "      <td>206.922504</td>\n",
       "      <td>17947.988114</td>\n",
       "      <td>7.048017</td>\n",
       "      <td>337.683896</td>\n",
       "      <td>601.985223</td>\n",
       "      <td>11.775110</td>\n",
       "      <td>58.176255</td>\n",
       "      <td>4.473887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
       "928   9.228582  180.944697  10345.399315     6.056989  349.557042   \n",
       "407   9.011589  228.919519  25208.151842     6.767010  339.290404   \n",
       "686   7.230845  177.574803  17864.689386     5.818229  343.593332   \n",
       "833   6.968651  193.926180  14936.503971     7.203401  309.447432   \n",
       "13    6.072983  150.174923  27331.361962     6.838223  299.415781   \n",
       "...        ...         ...           ...          ...         ...   \n",
       "77    9.597192  167.088976  21153.322827     7.944469  346.075016   \n",
       "348   5.895949  187.153617  37118.255436     4.600730  253.158469   \n",
       "806   7.156956  167.104430  30362.683948     9.990332  362.261636   \n",
       "1176  6.698154  198.286268  34675.862845     6.263602  360.232834   \n",
       "1105  6.903074  206.922504  17947.988114     7.048017  337.683896   \n",
       "\n",
       "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  \n",
       "928     397.043130       18.215464        53.976734   3.839185  \n",
       "407     380.145205       15.518323        66.142731   2.897293  \n",
       "686     367.689992       19.912950        59.303053   5.622018  \n",
       "833     447.450108       12.180626        66.622860   4.297914  \n",
       "13      379.761835       19.370807        76.509996   4.413974  \n",
       "...            ...             ...              ...        ...  \n",
       "77      335.197608       14.347676        50.642447   5.145153  \n",
       "348     531.169101       11.410184        77.286551   3.659653  \n",
       "806     432.030710        9.971476        94.984101   3.346057  \n",
       "1176    430.935009       12.176678        65.747444   3.758180  \n",
       "1105    601.985223       11.775110        58.176255   4.473887  \n",
       "\n",
       "[3276 rows x 9 columns]"
      ]
     },
     "execution_count": 1545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "y = data['Potability']\n",
    "X = data.drop(columns=['Potability'], axis = 1) ### Turbidity 낮은 상관계수 \n",
    "\n",
    "\n",
    "## test_size 확인 \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9,stratify=y, random_state=1)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "id": "b205c200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:06:41.079679Z",
     "start_time": "2022-07-21T06:06:41.059676Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1568,
   "id": "294e1605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:09:04.850066Z",
     "start_time": "2022-07-21T06:09:03.795648Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9465648854961832 0.7286585365853658\n",
      "0.48828125 0.5841121495327103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score,\n",
    "roc_auc_score, average_precision_score, precision_recall_curve, roc_curve,\n",
    "ConfusionMatrixDisplay,  PrecisionRecallDisplay, RocCurveDisplay)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300,\n",
    "                            criterion = 'entropy',\n",
    "                            max_depth=40,\n",
    "                            random_state=10,\n",
    "                            max_features=4,\n",
    "                            min_samples_leaf=5,\n",
    "                            n_jobs=-1\n",
    "                          )\n",
    "\n",
    "\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "rf_pred_train = rf.predict(X_train_scaled)\n",
    "rf_pred_test = rf.predict(X_test_scaled)\n",
    "\n",
    "print(accuracy_score(y_train, rf_pred_train), accuracy_score(y_test, rf_pred_test))\n",
    "print(recall_score(y_test, rf_pred_test), f1_score(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f66174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ba06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"딥러닝\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1569,
   "id": "b0607a9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:09:04.865065Z",
     "start_time": "2022-07-21T06:09:04.855064Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.layers import Dropout, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1570,
   "id": "60cb2946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:09:04.896074Z",
     "start_time": "2022-07-21T06:09:04.867067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2096, 9), (524, 9), (656, 9))"
      ]
     },
     "execution_count": 1570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=2)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1615,
   "id": "506389b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:16:22.521035Z",
     "start_time": "2022-07-21T06:16:22.495028Z"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 300\n",
    "N_BATCHS = 50\n",
    "\n",
    "N_TRAIN = X_train.shape[0]\n",
    "N_VAL = X_val.shape[0]\n",
    "N_TEST = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1755,
   "id": "1d6280d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:36:36.525168Z",
     "start_time": "2022-07-21T06:36:36.511569Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1756,
   "id": "6e9779d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:36:36.800650Z",
     "start_time": "2022-07-21T06:36:36.781647Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train)).shuffle(N_TRAIN).batch(N_BATCHS, drop_remainder=True)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_scaled, y_val)).batch(N_BATCHS)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_scaled, y_test)).batch(N_BATCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1800,
   "id": "ca4e497e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:45:30.746233Z",
     "start_time": "2022-07-21T06:45:30.735647Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_water_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=64, activation='LeakyReLU', input_shape=(9,)))\n",
    "    model.add(layers.Dense(units=32, activation='LeakyReLU'))\n",
    "    model.add(layers.Dense(units=16, activation='LeakyReLU'))\n",
    "    model.add(layers.Dense(units=8, activation='LeakyReLU'))\n",
    "    \n",
    "    model.add(layers.Dense(units=1, activation='sigmoid', name='Output_layer'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1808,
   "id": "b94b7e91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:47:06.349629Z",
     "start_time": "2022-07-21T06:47:06.270613Z"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "N_EPOCHS = 300\n",
    "N_BATCHS = 30\n",
    "\n",
    "\n",
    "model = create_water_model()\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=LEARNING_RATE), \n",
    "              loss='mean_squared_logarithmic_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1809,
   "id": "c1180ea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:47:49.129624Z",
     "start_time": "2022-07-21T06:47:06.482608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "69/69 [==============================] - 1s 3ms/step - loss: 0.1291 - accuracy: 0.5454 - val_loss: 0.1275 - val_accuracy: 0.5401\n",
      "Epoch 2/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.5758 - val_loss: 0.1239 - val_accuracy: 0.5935\n",
      "Epoch 3/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.6005 - val_loss: 0.1213 - val_accuracy: 0.6050\n",
      "Epoch 4/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.6068 - val_loss: 0.1194 - val_accuracy: 0.6069\n",
      "Epoch 5/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.6068 - val_loss: 0.1180 - val_accuracy: 0.6107\n",
      "Epoch 6/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.6097 - val_loss: 0.1170 - val_accuracy: 0.6088\n",
      "Epoch 7/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.6106 - val_loss: 0.1163 - val_accuracy: 0.6107\n",
      "Epoch 8/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.6097 - val_loss: 0.1157 - val_accuracy: 0.6107\n",
      "Epoch 9/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.6101 - val_loss: 0.1153 - val_accuracy: 0.6107\n",
      "Epoch 10/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.6111 - val_loss: 0.1149 - val_accuracy: 0.6107\n",
      "Epoch 11/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.6111 - val_loss: 0.1145 - val_accuracy: 0.6107\n",
      "Epoch 12/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.6092 - val_loss: 0.1143 - val_accuracy: 0.6107\n",
      "Epoch 13/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.6097 - val_loss: 0.1140 - val_accuracy: 0.6107\n",
      "Epoch 14/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.6111 - val_loss: 0.1138 - val_accuracy: 0.6107\n",
      "Epoch 15/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.6106 - val_loss: 0.1136 - val_accuracy: 0.6107\n",
      "Epoch 16/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1139 - accuracy: 0.6092 - val_loss: 0.1134 - val_accuracy: 0.6107\n",
      "Epoch 17/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.6116 - val_loss: 0.1132 - val_accuracy: 0.6107\n",
      "Epoch 18/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.6106 - val_loss: 0.1130 - val_accuracy: 0.6107\n",
      "Epoch 19/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.6087 - val_loss: 0.1128 - val_accuracy: 0.6107\n",
      "Epoch 20/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.6101 - val_loss: 0.1127 - val_accuracy: 0.6107\n",
      "Epoch 21/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.6097 - val_loss: 0.1125 - val_accuracy: 0.6107\n",
      "Epoch 22/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.6092 - val_loss: 0.1123 - val_accuracy: 0.6107\n",
      "Epoch 23/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.6082 - val_loss: 0.1122 - val_accuracy: 0.6107\n",
      "Epoch 24/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.6097 - val_loss: 0.1120 - val_accuracy: 0.6107\n",
      "Epoch 25/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.6087 - val_loss: 0.1118 - val_accuracy: 0.6107\n",
      "Epoch 26/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.6101 - val_loss: 0.1117 - val_accuracy: 0.6107\n",
      "Epoch 27/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.6082 - val_loss: 0.1115 - val_accuracy: 0.6107\n",
      "Epoch 28/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.6106 - val_loss: 0.1113 - val_accuracy: 0.6107\n",
      "Epoch 29/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.6092 - val_loss: 0.1112 - val_accuracy: 0.6107\n",
      "Epoch 30/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.6082 - val_loss: 0.1110 - val_accuracy: 0.6107\n",
      "Epoch 31/300\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.6092 - val_loss: 0.1109 - val_accuracy: 0.6107\n",
      "Epoch 32/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.6087 - val_loss: 0.1107 - val_accuracy: 0.6107\n",
      "Epoch 33/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.6106 - val_loss: 0.1106 - val_accuracy: 0.6107\n",
      "Epoch 34/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.6135 - val_loss: 0.1104 - val_accuracy: 0.6107\n",
      "Epoch 35/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.6126 - val_loss: 0.1102 - val_accuracy: 0.6107\n",
      "Epoch 36/300\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.6101 - val_loss: 0.1101 - val_accuracy: 0.6107\n",
      "Epoch 37/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.6111 - val_loss: 0.1099 - val_accuracy: 0.6107\n",
      "Epoch 38/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.6111 - val_loss: 0.1097 - val_accuracy: 0.6107\n",
      "Epoch 39/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.6092 - val_loss: 0.1096 - val_accuracy: 0.6107\n",
      "Epoch 40/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.6135 - val_loss: 0.1094 - val_accuracy: 0.6107\n",
      "Epoch 41/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.6106 - val_loss: 0.1092 - val_accuracy: 0.6126\n",
      "Epoch 42/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.6106 - val_loss: 0.1091 - val_accuracy: 0.6126\n",
      "Epoch 43/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.6145 - val_loss: 0.1089 - val_accuracy: 0.6126\n",
      "Epoch 44/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.6116 - val_loss: 0.1087 - val_accuracy: 0.6126\n",
      "Epoch 45/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.6145 - val_loss: 0.1086 - val_accuracy: 0.6145\n",
      "Epoch 46/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.6145 - val_loss: 0.1084 - val_accuracy: 0.6164\n",
      "Epoch 47/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.6155 - val_loss: 0.1082 - val_accuracy: 0.6145\n",
      "Epoch 48/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.6164 - val_loss: 0.1080 - val_accuracy: 0.6145\n",
      "Epoch 49/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.6159 - val_loss: 0.1078 - val_accuracy: 0.6145\n",
      "Epoch 50/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.6179 - val_loss: 0.1076 - val_accuracy: 0.6145\n",
      "Epoch 51/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.6164 - val_loss: 0.1074 - val_accuracy: 0.6145\n",
      "Epoch 52/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.6179 - val_loss: 0.1072 - val_accuracy: 0.6145\n",
      "Epoch 53/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.6188 - val_loss: 0.1071 - val_accuracy: 0.6183\n",
      "Epoch 54/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.6188 - val_loss: 0.1069 - val_accuracy: 0.6183\n",
      "Epoch 55/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.6213 - val_loss: 0.1067 - val_accuracy: 0.6183\n",
      "Epoch 56/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.6217 - val_loss: 0.1065 - val_accuracy: 0.6202\n",
      "Epoch 57/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.6208 - val_loss: 0.1063 - val_accuracy: 0.6202\n",
      "Epoch 58/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.6217 - val_loss: 0.1061 - val_accuracy: 0.6202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.6242 - val_loss: 0.1059 - val_accuracy: 0.6240\n",
      "Epoch 60/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.6261 - val_loss: 0.1056 - val_accuracy: 0.6260\n",
      "Epoch 61/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.6256 - val_loss: 0.1054 - val_accuracy: 0.6260\n",
      "Epoch 62/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.6280 - val_loss: 0.1052 - val_accuracy: 0.6279\n",
      "Epoch 63/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.6271 - val_loss: 0.1050 - val_accuracy: 0.6279\n",
      "Epoch 64/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.6304 - val_loss: 0.1048 - val_accuracy: 0.6279\n",
      "Epoch 65/300\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.6324 - val_loss: 0.1046 - val_accuracy: 0.6279\n",
      "Epoch 66/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.6304 - val_loss: 0.1043 - val_accuracy: 0.6279\n",
      "Epoch 67/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.6300 - val_loss: 0.1041 - val_accuracy: 0.6279\n",
      "Epoch 68/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.6309 - val_loss: 0.1039 - val_accuracy: 0.6279\n",
      "Epoch 69/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.6329 - val_loss: 0.1037 - val_accuracy: 0.6317\n",
      "Epoch 70/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.6353 - val_loss: 0.1034 - val_accuracy: 0.6317\n",
      "Epoch 71/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.6329 - val_loss: 0.1032 - val_accuracy: 0.6336\n",
      "Epoch 72/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.6338 - val_loss: 0.1030 - val_accuracy: 0.6355\n",
      "Epoch 73/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.6338 - val_loss: 0.1027 - val_accuracy: 0.6374\n",
      "Epoch 74/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.6353 - val_loss: 0.1025 - val_accuracy: 0.6374\n",
      "Epoch 75/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 0.6372 - val_loss: 0.1023 - val_accuracy: 0.6374\n",
      "Epoch 76/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.6382 - val_loss: 0.1020 - val_accuracy: 0.6393\n",
      "Epoch 77/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.6382 - val_loss: 0.1018 - val_accuracy: 0.6412\n",
      "Epoch 78/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.6377 - val_loss: 0.1016 - val_accuracy: 0.6412\n",
      "Epoch 79/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.6411 - val_loss: 0.1013 - val_accuracy: 0.6412\n",
      "Epoch 80/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.6411 - val_loss: 0.1011 - val_accuracy: 0.6431\n",
      "Epoch 81/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.6411 - val_loss: 0.1009 - val_accuracy: 0.6431\n",
      "Epoch 82/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.6430 - val_loss: 0.1007 - val_accuracy: 0.6431\n",
      "Epoch 83/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.6425 - val_loss: 0.1004 - val_accuracy: 0.6431\n",
      "Epoch 84/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.6469 - val_loss: 0.1002 - val_accuracy: 0.6431\n",
      "Epoch 85/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.6478 - val_loss: 0.1000 - val_accuracy: 0.6489\n",
      "Epoch 86/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.6502 - val_loss: 0.0997 - val_accuracy: 0.6489\n",
      "Epoch 87/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.6488 - val_loss: 0.0995 - val_accuracy: 0.6527\n",
      "Epoch 88/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.6507 - val_loss: 0.0993 - val_accuracy: 0.6527\n",
      "Epoch 89/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.6522 - val_loss: 0.0991 - val_accuracy: 0.6527\n",
      "Epoch 90/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.6507 - val_loss: 0.0988 - val_accuracy: 0.6527\n",
      "Epoch 91/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.6522 - val_loss: 0.0986 - val_accuracy: 0.6527\n",
      "Epoch 92/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.6556 - val_loss: 0.0984 - val_accuracy: 0.6527\n",
      "Epoch 93/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.6565 - val_loss: 0.0981 - val_accuracy: 0.6565\n",
      "Epoch 94/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.6599 - val_loss: 0.0979 - val_accuracy: 0.6565\n",
      "Epoch 95/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.6599 - val_loss: 0.0977 - val_accuracy: 0.6565\n",
      "Epoch 96/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.6604 - val_loss: 0.0974 - val_accuracy: 0.6603\n",
      "Epoch 97/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.6647 - val_loss: 0.0972 - val_accuracy: 0.6622\n",
      "Epoch 98/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.6589 - val_loss: 0.0970 - val_accuracy: 0.6641\n",
      "Epoch 99/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.6643 - val_loss: 0.0968 - val_accuracy: 0.6660\n",
      "Epoch 100/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.6647 - val_loss: 0.0965 - val_accuracy: 0.6679\n",
      "Epoch 101/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.6676 - val_loss: 0.0963 - val_accuracy: 0.6679\n",
      "Epoch 102/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.6671 - val_loss: 0.0961 - val_accuracy: 0.6679\n",
      "Epoch 103/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.6652 - val_loss: 0.0959 - val_accuracy: 0.6718\n",
      "Epoch 104/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.6671 - val_loss: 0.0957 - val_accuracy: 0.6737\n",
      "Epoch 105/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.6715 - val_loss: 0.0955 - val_accuracy: 0.6737\n",
      "Epoch 106/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.6720 - val_loss: 0.0953 - val_accuracy: 0.6756\n",
      "Epoch 107/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.6739 - val_loss: 0.0951 - val_accuracy: 0.6756\n",
      "Epoch 108/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.6739 - val_loss: 0.0949 - val_accuracy: 0.6756\n",
      "Epoch 109/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.6734 - val_loss: 0.0947 - val_accuracy: 0.6756\n",
      "Epoch 110/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.6778 - val_loss: 0.0945 - val_accuracy: 0.6756\n",
      "Epoch 111/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.6744 - val_loss: 0.0943 - val_accuracy: 0.6756\n",
      "Epoch 112/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.6773 - val_loss: 0.0940 - val_accuracy: 0.6775\n",
      "Epoch 113/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.6773 - val_loss: 0.0938 - val_accuracy: 0.6775\n",
      "Epoch 114/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.6792 - val_loss: 0.0937 - val_accuracy: 0.6794\n",
      "Epoch 115/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.6807 - val_loss: 0.0934 - val_accuracy: 0.6775\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.6812 - val_loss: 0.0932 - val_accuracy: 0.6775\n",
      "Epoch 117/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.6850 - val_loss: 0.0931 - val_accuracy: 0.6775\n",
      "Epoch 118/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.6831 - val_loss: 0.0929 - val_accuracy: 0.6813\n",
      "Epoch 119/300\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.6874 - val_loss: 0.0927 - val_accuracy: 0.6832\n",
      "Epoch 120/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.6855 - val_loss: 0.0925 - val_accuracy: 0.6832\n",
      "Epoch 121/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.6855 - val_loss: 0.0923 - val_accuracy: 0.6851\n",
      "Epoch 122/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.6860 - val_loss: 0.0921 - val_accuracy: 0.6851\n",
      "Epoch 123/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.6889 - val_loss: 0.0920 - val_accuracy: 0.6851\n",
      "Epoch 124/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.6908 - val_loss: 0.0918 - val_accuracy: 0.6851\n",
      "Epoch 125/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.6913 - val_loss: 0.0916 - val_accuracy: 0.6870\n",
      "Epoch 126/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0927 - accuracy: 0.6918 - val_loss: 0.0914 - val_accuracy: 0.6870\n",
      "Epoch 127/300\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.6918 - val_loss: 0.0913 - val_accuracy: 0.6870\n",
      "Epoch 128/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.6899 - val_loss: 0.0911 - val_accuracy: 0.6908\n",
      "Epoch 129/300\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.6908 - val_loss: 0.0909 - val_accuracy: 0.6947\n",
      "Epoch 130/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.6947 - val_loss: 0.0907 - val_accuracy: 0.6985\n",
      "Epoch 131/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0921 - accuracy: 0.6923 - val_loss: 0.0906 - val_accuracy: 0.7004\n",
      "Epoch 132/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.6981 - val_loss: 0.0904 - val_accuracy: 0.7042\n",
      "Epoch 133/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.7019 - val_loss: 0.0903 - val_accuracy: 0.7023\n",
      "Epoch 134/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.7000 - val_loss: 0.0901 - val_accuracy: 0.7061\n",
      "Epoch 135/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.6990 - val_loss: 0.0900 - val_accuracy: 0.7061\n",
      "Epoch 136/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.7029 - val_loss: 0.0898 - val_accuracy: 0.7099\n",
      "Epoch 137/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.7063 - val_loss: 0.0897 - val_accuracy: 0.7099\n",
      "Epoch 138/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.7034 - val_loss: 0.0895 - val_accuracy: 0.7080\n",
      "Epoch 139/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.7048 - val_loss: 0.0894 - val_accuracy: 0.7080\n",
      "Epoch 140/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.7029 - val_loss: 0.0893 - val_accuracy: 0.7080\n",
      "Epoch 141/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.7092 - val_loss: 0.0892 - val_accuracy: 0.7080\n",
      "Epoch 142/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.7063 - val_loss: 0.0890 - val_accuracy: 0.7099\n",
      "Epoch 143/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.7101 - val_loss: 0.0889 - val_accuracy: 0.7099\n",
      "Epoch 144/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.7097 - val_loss: 0.0888 - val_accuracy: 0.7099\n",
      "Epoch 145/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.7101 - val_loss: 0.0886 - val_accuracy: 0.7118\n",
      "Epoch 146/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.7068 - val_loss: 0.0885 - val_accuracy: 0.7099\n",
      "Epoch 147/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.7101 - val_loss: 0.0884 - val_accuracy: 0.7118\n",
      "Epoch 148/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.7130 - val_loss: 0.0883 - val_accuracy: 0.7118\n",
      "Epoch 149/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.7116 - val_loss: 0.0882 - val_accuracy: 0.7118\n",
      "Epoch 150/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.7150 - val_loss: 0.0881 - val_accuracy: 0.7118\n",
      "Epoch 151/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.7126 - val_loss: 0.0879 - val_accuracy: 0.7118\n",
      "Epoch 152/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.7130 - val_loss: 0.0879 - val_accuracy: 0.7137\n",
      "Epoch 153/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.7130 - val_loss: 0.0878 - val_accuracy: 0.7137\n",
      "Epoch 154/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.7150 - val_loss: 0.0877 - val_accuracy: 0.7156\n",
      "Epoch 155/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.7145 - val_loss: 0.0876 - val_accuracy: 0.7137\n",
      "Epoch 156/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.7126 - val_loss: 0.0875 - val_accuracy: 0.7156\n",
      "Epoch 157/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.7159 - val_loss: 0.0874 - val_accuracy: 0.7156\n",
      "Epoch 158/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.7126 - val_loss: 0.0873 - val_accuracy: 0.7156\n",
      "Epoch 159/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.7145 - val_loss: 0.0871 - val_accuracy: 0.7176\n",
      "Epoch 160/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.7130 - val_loss: 0.0870 - val_accuracy: 0.7176\n",
      "Epoch 161/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.7174 - val_loss: 0.0869 - val_accuracy: 0.7176\n",
      "Epoch 162/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.7159 - val_loss: 0.0869 - val_accuracy: 0.7176\n",
      "Epoch 163/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.7150 - val_loss: 0.0868 - val_accuracy: 0.7176\n",
      "Epoch 164/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.7179 - val_loss: 0.0867 - val_accuracy: 0.7176\n",
      "Epoch 165/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.7184 - val_loss: 0.0866 - val_accuracy: 0.7176\n",
      "Epoch 166/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.7198 - val_loss: 0.0865 - val_accuracy: 0.7176\n",
      "Epoch 167/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.7188 - val_loss: 0.0865 - val_accuracy: 0.7176\n",
      "Epoch 168/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.7203 - val_loss: 0.0864 - val_accuracy: 0.7176\n",
      "Epoch 169/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.7203 - val_loss: 0.0863 - val_accuracy: 0.7195\n",
      "Epoch 170/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.7213 - val_loss: 0.0863 - val_accuracy: 0.7176\n",
      "Epoch 171/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.7217 - val_loss: 0.0862 - val_accuracy: 0.7195\n",
      "Epoch 172/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.7208 - val_loss: 0.0861 - val_accuracy: 0.7176\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.7222 - val_loss: 0.0861 - val_accuracy: 0.7176\n",
      "Epoch 174/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.7213 - val_loss: 0.0860 - val_accuracy: 0.7176\n",
      "Epoch 175/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.7217 - val_loss: 0.0860 - val_accuracy: 0.7176\n",
      "Epoch 176/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.7237 - val_loss: 0.0859 - val_accuracy: 0.7176\n",
      "Epoch 177/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.7203 - val_loss: 0.0859 - val_accuracy: 0.7176\n",
      "Epoch 178/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.7256 - val_loss: 0.0858 - val_accuracy: 0.7176\n",
      "Epoch 179/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.7251 - val_loss: 0.0857 - val_accuracy: 0.7176\n",
      "Epoch 180/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.7271 - val_loss: 0.0857 - val_accuracy: 0.7176\n",
      "Epoch 181/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.7242 - val_loss: 0.0856 - val_accuracy: 0.7195\n",
      "Epoch 182/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.7242 - val_loss: 0.0855 - val_accuracy: 0.7195\n",
      "Epoch 183/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.7271 - val_loss: 0.0855 - val_accuracy: 0.7176\n",
      "Epoch 184/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.7251 - val_loss: 0.0855 - val_accuracy: 0.7176\n",
      "Epoch 185/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.7242 - val_loss: 0.0854 - val_accuracy: 0.7195\n",
      "Epoch 186/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.7266 - val_loss: 0.0853 - val_accuracy: 0.7214\n",
      "Epoch 187/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.7256 - val_loss: 0.0853 - val_accuracy: 0.7195\n",
      "Epoch 188/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.7280 - val_loss: 0.0852 - val_accuracy: 0.7195\n",
      "Epoch 189/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.7280 - val_loss: 0.0852 - val_accuracy: 0.7195\n",
      "Epoch 190/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.7295 - val_loss: 0.0852 - val_accuracy: 0.7195\n",
      "Epoch 191/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.7280 - val_loss: 0.0851 - val_accuracy: 0.7195\n",
      "Epoch 192/300\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.7295 - val_loss: 0.0851 - val_accuracy: 0.7195\n",
      "Epoch 193/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.7256 - val_loss: 0.0850 - val_accuracy: 0.7214\n",
      "Epoch 194/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.7275 - val_loss: 0.0850 - val_accuracy: 0.7233\n",
      "Epoch 195/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.7314 - val_loss: 0.0850 - val_accuracy: 0.7195\n",
      "Epoch 196/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.7285 - val_loss: 0.0850 - val_accuracy: 0.7214\n",
      "Epoch 197/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.7290 - val_loss: 0.0849 - val_accuracy: 0.7271\n",
      "Epoch 198/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.7295 - val_loss: 0.0849 - val_accuracy: 0.7195\n",
      "Epoch 199/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.7295 - val_loss: 0.0848 - val_accuracy: 0.7195\n",
      "Epoch 200/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.7280 - val_loss: 0.0848 - val_accuracy: 0.7195\n",
      "Epoch 201/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.7290 - val_loss: 0.0848 - val_accuracy: 0.7195\n",
      "Epoch 202/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.7300 - val_loss: 0.0847 - val_accuracy: 0.7214\n",
      "Epoch 203/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.7295 - val_loss: 0.0847 - val_accuracy: 0.7214\n",
      "Epoch 204/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0855 - accuracy: 0.7304 - val_loss: 0.0847 - val_accuracy: 0.7271\n",
      "Epoch 205/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.7304 - val_loss: 0.0847 - val_accuracy: 0.7233\n",
      "Epoch 206/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.7295 - val_loss: 0.0847 - val_accuracy: 0.7233\n",
      "Epoch 207/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.7295 - val_loss: 0.0846 - val_accuracy: 0.7233\n",
      "Epoch 208/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.7329 - val_loss: 0.0846 - val_accuracy: 0.7233\n",
      "Epoch 209/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.7304 - val_loss: 0.0845 - val_accuracy: 0.7233\n",
      "Epoch 210/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.7309 - val_loss: 0.0845 - val_accuracy: 0.7233\n",
      "Epoch 211/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.7367 - val_loss: 0.0845 - val_accuracy: 0.7233\n",
      "Epoch 212/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.7314 - val_loss: 0.0845 - val_accuracy: 0.7233\n",
      "Epoch 213/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.7295 - val_loss: 0.0844 - val_accuracy: 0.7233\n",
      "Epoch 214/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.7309 - val_loss: 0.0844 - val_accuracy: 0.7233\n",
      "Epoch 215/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.7319 - val_loss: 0.0844 - val_accuracy: 0.7233\n",
      "Epoch 216/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.7304 - val_loss: 0.0844 - val_accuracy: 0.7252\n",
      "Epoch 217/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.7348 - val_loss: 0.0844 - val_accuracy: 0.7233\n",
      "Epoch 218/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.7300 - val_loss: 0.0844 - val_accuracy: 0.7309\n",
      "Epoch 219/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.7319 - val_loss: 0.0844 - val_accuracy: 0.7271\n",
      "Epoch 220/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.7329 - val_loss: 0.0844 - val_accuracy: 0.7252\n",
      "Epoch 221/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.7319 - val_loss: 0.0843 - val_accuracy: 0.7252\n",
      "Epoch 222/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.7343 - val_loss: 0.0843 - val_accuracy: 0.7233\n",
      "Epoch 223/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.7348 - val_loss: 0.0843 - val_accuracy: 0.7252\n",
      "Epoch 224/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.7362 - val_loss: 0.0842 - val_accuracy: 0.7271\n",
      "Epoch 225/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.7372 - val_loss: 0.0842 - val_accuracy: 0.7252\n",
      "Epoch 226/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.7329 - val_loss: 0.0842 - val_accuracy: 0.7252\n",
      "Epoch 227/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.7353 - val_loss: 0.0842 - val_accuracy: 0.7252\n",
      "Epoch 228/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.7377 - val_loss: 0.0841 - val_accuracy: 0.7271\n",
      "Epoch 229/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.7329 - val_loss: 0.0842 - val_accuracy: 0.7271\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.7353 - val_loss: 0.0842 - val_accuracy: 0.7271\n",
      "Epoch 231/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.7338 - val_loss: 0.0841 - val_accuracy: 0.7271\n",
      "Epoch 232/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.7333 - val_loss: 0.0841 - val_accuracy: 0.7271\n",
      "Epoch 233/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.7343 - val_loss: 0.0841 - val_accuracy: 0.7271\n",
      "Epoch 234/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.7333 - val_loss: 0.0841 - val_accuracy: 0.7290\n",
      "Epoch 235/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.7353 - val_loss: 0.0842 - val_accuracy: 0.7271\n",
      "Epoch 236/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.7357 - val_loss: 0.0842 - val_accuracy: 0.7252\n",
      "Epoch 237/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.7343 - val_loss: 0.0841 - val_accuracy: 0.7271\n",
      "Epoch 238/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.7386 - val_loss: 0.0841 - val_accuracy: 0.7290\n",
      "Epoch 239/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.7353 - val_loss: 0.0841 - val_accuracy: 0.7290\n",
      "Epoch 240/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.7372 - val_loss: 0.0841 - val_accuracy: 0.7290\n",
      "Epoch 241/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.7353 - val_loss: 0.0840 - val_accuracy: 0.7271\n",
      "Epoch 242/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.7377 - val_loss: 0.0840 - val_accuracy: 0.7290\n",
      "Epoch 243/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.7372 - val_loss: 0.0841 - val_accuracy: 0.7271\n",
      "Epoch 244/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.7386 - val_loss: 0.0840 - val_accuracy: 0.7271\n",
      "Epoch 245/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.7362 - val_loss: 0.0840 - val_accuracy: 0.7290\n",
      "Epoch 246/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.7362 - val_loss: 0.0840 - val_accuracy: 0.7271\n",
      "Epoch 247/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.7386 - val_loss: 0.0840 - val_accuracy: 0.7290\n",
      "Epoch 248/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.7362 - val_loss: 0.0840 - val_accuracy: 0.7290\n",
      "Epoch 249/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.7382 - val_loss: 0.0840 - val_accuracy: 0.7271\n",
      "Epoch 250/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.7367 - val_loss: 0.0840 - val_accuracy: 0.7271\n",
      "Epoch 251/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.7377 - val_loss: 0.0840 - val_accuracy: 0.7271\n",
      "Epoch 252/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.7367 - val_loss: 0.0840 - val_accuracy: 0.7290\n",
      "Epoch 253/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.7391 - val_loss: 0.0839 - val_accuracy: 0.7271\n",
      "Epoch 254/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.7396 - val_loss: 0.0839 - val_accuracy: 0.7271\n",
      "Epoch 255/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.7386 - val_loss: 0.0839 - val_accuracy: 0.7271\n",
      "Epoch 256/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.7406 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 257/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.7382 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 258/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.7415 - val_loss: 0.0840 - val_accuracy: 0.7290\n",
      "Epoch 259/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.7401 - val_loss: 0.0839 - val_accuracy: 0.7271\n",
      "Epoch 260/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.7411 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 261/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.7406 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 262/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.7396 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 263/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.7415 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 264/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.7430 - val_loss: 0.0838 - val_accuracy: 0.7271\n",
      "Epoch 265/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.7406 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 266/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.7411 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 267/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.7415 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 268/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.7430 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 269/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.7401 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 270/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.7391 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 271/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.7440 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 272/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.7415 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 273/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.7415 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 274/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.7372 - val_loss: 0.0838 - val_accuracy: 0.7271\n",
      "Epoch 275/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.7420 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 276/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.7415 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 277/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.7406 - val_loss: 0.0838 - val_accuracy: 0.7271\n",
      "Epoch 278/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.7425 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 279/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.7415 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 280/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.7440 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 281/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.7464 - val_loss: 0.0838 - val_accuracy: 0.7271\n",
      "Epoch 282/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.7473 - val_loss: 0.0838 - val_accuracy: 0.7271\n",
      "Epoch 283/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.7440 - val_loss: 0.0838 - val_accuracy: 0.7271\n",
      "Epoch 284/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.7449 - val_loss: 0.0839 - val_accuracy: 0.7271\n",
      "Epoch 285/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.7430 - val_loss: 0.0839 - val_accuracy: 0.7271\n",
      "Epoch 286/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.7449 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.7464 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 288/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.7459 - val_loss: 0.0839 - val_accuracy: 0.7271\n",
      "Epoch 289/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.7411 - val_loss: 0.0839 - val_accuracy: 0.7290\n",
      "Epoch 290/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.7459 - val_loss: 0.0838 - val_accuracy: 0.7309\n",
      "Epoch 291/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.7502 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 292/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.7444 - val_loss: 0.0838 - val_accuracy: 0.7309\n",
      "Epoch 293/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.7473 - val_loss: 0.0838 - val_accuracy: 0.7309\n",
      "Epoch 294/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.7507 - val_loss: 0.0838 - val_accuracy: 0.7309\n",
      "Epoch 295/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.7483 - val_loss: 0.0838 - val_accuracy: 0.7309\n",
      "Epoch 296/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.7493 - val_loss: 0.0838 - val_accuracy: 0.7309\n",
      "Epoch 297/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.7473 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 298/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.7498 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 299/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.7473 - val_loss: 0.0838 - val_accuracy: 0.7290\n",
      "Epoch 300/300\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.7498 - val_loss: 0.0838 - val_accuracy: 0.7309\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_dataset, epochs=N_EPOCHS, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1810,
   "id": "d62da816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:47:52.380194Z",
     "start_time": "2022-07-21T06:47:52.239645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbsAAAGHCAYAAAAp0fzIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABHgUlEQVR4nO3dd3RU1d7G8e+e9F5poZdIL0JQiiAiIIiIBTuCDRX12l/LRb0qFrw2rr0gKipYwAIWEEGqCIbeews1hJDeZ79/TMCAAUEymWTyfNZiZeacM2d+24M82afsbay1iIiIeDOHpwsQERFxN4WdiIh4PYWdiIh4PYWdiIh4PYWdiIh4PYWdiIh4PYWdiIh4PYWdiAcZYxoYY6wx5kFP1yLizRR2IiLi9RR2IiLi9RR2IiLi9RR2IpWAMSbCGPOsMWadMSbXGJNqjJlqjOlWyrZRxphRxpiNxdvuNsa8ecw2HY0xk40xe40x2caYVcaYi8uvRSLly9fTBYjIiRljYoE5QEPgQ2A5UA0YCvxqjLnGWvtV8baBwFygJvAGkAycAXQtsb/zgJ+BRcAzQDDQBWgLTC6fVomUL4WdSMX3Gq7AOsda+/vhhcaYV4EFwPvGmGnW2nSgF9ASGGStnVRiW78S+7sTOAT0tNbmHWcbEa+i05giFVhxr+5K4OOSQQdgrc0C/gNEAJcc/kjxz8Bjti0ouVtcv+j6nWAbEa+isBOp2BIAH2D6cdbPK/7ZtvjnTCAJV29vpDGmeimfGQdEAouMMVcaY3zKsF6RCklhJ1KxxRT/TCptpbU2GSgEworfZ+G6/vY98G9ghzHmbWNMdInPfAcMxNXD+wLYbIy50W0tEKkAFHYiFVtm8c9apa0sPs3pC6QeXmat3WmtvRLXdb6xwK3AbGOMb4ltJgMtgP7APmCsMeYRt7RApAJQ2IlUbEuKf55/nPVdin8uPHaFtXaztfYO4CGgFXDOMeuttfbH4n0sA24vi4JFKiKFnUgFZq3dCUwFbjbGdCy5zhgTBDwFbMd12hJjTK2SPbhiuw9/pHibesd8RxGwnz9vbhHxOnr0QKRiSDDG3FDK8qm4elzzcZ2KPPycXSwwBIgDLrDW5hdvfwHwb2PMF8AOoDYwHFjFnzezfGSMyQF+AXKATkAfXNf4RLySsdZ6ugaRKssY0wDYeoJNzrPWzjLG1AQeBwbgemD8IK47NJ+21m4ssb/mwAvA2UA4sBP4GvivtfZg8TY3AncDTXDd3LIGeMNaO6FsWydScSjsRETE6+manYiIeD2FnYiIeD2FnYiIeD2FnYiIeD2FnYiIeL1K+5xdbGysbdCggafLEBGRCmTx4sUHrLXVjl1eacOuQYMGJCYmeroMERGpQIwx20tbrtOYIiLi9RR2IiLi9RR2IiLi9SrtNTsREXcqKCggKSmJ3NxcT5cipQgMDKROnTr4+fmd1PZuCztjzEige/F33GqtXV1iXXNgJDDGWju1eNl/gQRcMy4/bK2d6a7aRET+TlJSEmFhYTRo0ABjNPtRRWKtJSUlhaSkJBo2bHhSn3HLaUxjTDeghrX2XOA24MUS6+oDj/DnDMyHjbTW9gQuLV4vIuIxubm5xMTEKOgqIGMMMTExp9Trdtc1uz7ABABr7Sog+vAKa+12a+1QYFvJD1hrM4pfngGscFNdIiInTUFXcZ3qsXFX2FUHkku8LzTGnPC7jDG9jTFLgLeBd46zza3GmERjTGJycnJpm4iIeIVbbrmFHj16EBkZSffu3enRowcn8+/egw8+eErf06lTp39aYqXirmt2aUBUifdOa63zRB+w1k4Hphef5vwS1+STx27zHvAeQEJCgibiExGvNWbMGAB69OjB1KlTCQwMPLLOWnvcns1LL71ULvVVNu4Ku7nAIGCuMaYFkHSijY0xvoC/tTYbOAD4uKkuEZFT9tSU1azZnV6m+2wRF85/BrQ8pc/06NGDHj16sGjRIn788Ueuvvpq9u3bR05ODuPHj6dRo0Z06tSJ33//nY8++ohFixaxc+dONm/ezNNPP82gQYNO6ntGjhzJzz//TFFREWeddRajR49m06ZNDBs2jMLCQs4991yeeeYZhg8fzooVK3A6ncyZM+ek74z0BHeF3Q/AhcaYuUAGcJsx5gXgcWttfinbBwBTik91WuBRN9UlIlKpdenShSeffBKA119/nWrVqvHxxx8zYcIERowYcdS2hw4dYsqUKezfv58BAwacVNhNnz6dbdu2MWfOHIwx3HnnnUyZMoUtW7YwePBgbr75ZpxOJ6mpqaxZs4b58+efsKdZUbgl7IpPWQ4/ZvHDx2zzZInXWUBPd9RyPAVFTn7bnELDmBDqxQSX51eLSCVzqj0wd+rSpQsA+/fv5+mnnyY0NJTdu3cTFxf3l227desGQPXq1U96/8uWLaN///5HwqtXr16sW7eOO++8k1deeYX777+fYcOG0bx5cx544AHuuusuOnfuzHXXXVcGrXOfKjuCSkGRk6FjFzF19R5PlyIictJ8fV19lE8++YSuXbsyatQo2rZtW+q2JXtbJ9vzatmyJVOnTj3yfubMmZx55pkYY3jssccYOXIkt9xyCwUFBVx44YW88cYbTJs2jZUrV55Gq9yvyo6gEujrgzGQmVfk6VJERE5Zr169GDx4MJ999hnNmjU7EoKn6uDBg/To0QOAJk2aMGbMGObPn0/nzp0JCAigV69e9OrViw8++IAxY8YQGBjI9ddfT0pKCgMHDiQkJITY2Fji4+PLsHVlz1hbOW9qTEhIsKc7xU/LJ6ZyzVn1eOyiFmVUlYh4i7Vr19K8eXNPlyEnUNoxMsYsttYmHLttlT2NCRAc4EtWvnp2IiLerkqHXYi/D9n5hZ4uQ0RE3KxKh12wvy9ZumYnIuL1qnTYhQSoZyciUhVU6bAL9tc1OxGRqqBKh11IgA/ZeerZiYh4u6obds4i6tvd+Ocd9HQlIiJ/0a9fP9auXXvUsq5du5Y688GsWbN45BHXNKCPPfZYqfO89ejR44Tzv82bN4+iIteZrnHjxrFixenPtPbkk08e9YC6J1XdsMvP4uFNg+mZrwnRRaTiGTp0KJ988smR92vWrKFWrVpUq1bthJ975plnjpoh4WQ99thjFBQUADBkyBDatGlzyvuoyKrsCCr4hwIQUJjl4UJEpML76RHYW8bDYdVsDf1GHXf1JZdcwvPPP8+zzz6LMYaPP/6YG2+8kcTERB599FGys7Np2rQpY8eOPepzh6cE8vX15bbbbmPTpk3UqlWL9HTXrA1paWkMGTKEtLQ0nE4n3333HW+99RbLli2jT58+PPnkk8yZM4dOnTrRt29fxowZw0cffYTD4aBevXp88MEHBAQEkJCQQEJCAsuWLaNhw4ZMmDDhpJr922+/MWLECKy1+Pn58e6779KoUaO/zKDw008/MWrUKBwOBw888ACXXnrpP/9vTVXu2Tkc5PuEEGSzyS884VR7IiLlLjAwkM6dOzNnzhycTie//vorffv2pWHDhkybNo158+axfft2du3aVernP/roIxo1asTs2bN599132bt3LwABAQF8+umnzJo1i/PPP58ff/yRESNG0K5dO37++Wd69vxzTP7169fz9ddfM2vWLObMmUPbtm157733ANi0aRNPP/00v//+O1lZWSc9Nubdd9/Nl19+yaxZs3juuef4v//7v6NmUPjtt9/w8/Pjww8/5JNPPmHevHkMHDjwNP9rVuWeHVDgG0JoXg7Z+YX4+/p7uhwRqahO0ANzpxtuuIExY8aQl5dHz5498fHxYeHChfz000+EhoZy8OBBMjIySv3skiVLGDZsGAARERFHxq7cuXMno0ePJiwsjHXr1lGjRo3jfv+KFSvo1avXkXE3e/XqdWRS2aZNmx6ZTaF58+YcPPj39z8kJycTFxd35FRsx44d2b17N1FRUX+ZQWH06NG88cYbBAUFcf/99xMZGXly/9GOo+r27IBCv1BCTbYePxCRCqlTp06sWrWKjz76iJtuugmAp556ildffZWRI0eecCaD+vXrM2/ePMAVMqtWrQLgtddeY/DgwYwaNYq6dese2d7Hx4e8vLyj9tG8eXNmzJhx5MaVwzMgwF9nVDiZcZZjY2PZuXMnKSkpACxevJjGjRuXOoNC9erVefHFF+nRowcjR478233/nSrds3P6hRJGjh4/EJEK65JLLmHq1KmcccYZAFx66aW0b9+eNm3aULt27eN+7vbbb+eaa67hiy++oEmTJrRo4Rrw/uKLL+bmm28mPj7+qM8PGDCA7t278/rrrx9Z1qpVK/r160fXrl0JDg6mZcuWjB49+pTqf+ihhxg1ytUzHjNmDKNHj2bgwIH4+/sTGRnJW2+9VeoMCvfddx+rV6/Gx8eHZ5999pS+szRVetaDg29fyLY9+3AMm0G7upFlU5iIeAXNelDxadaDkxUQRqh6diIiXq9Kh50JDCfE5OqanYiIl6vSYecIDHNds9Ng0CIiXq1Kh51PUDih5JCVq7ATkb+qrPc0VAWnemyqdNj5BofjMJb8nNKfUxGRqiswMJCUlBQFXgVkrSUlJeWUhkWr0o8e+AdHAlCYne7ZQkSkwqlTpw5JSUmlDrwsnhcYGEidOnVOevsqHXaOwHAAinLTPFyJiFQ0fn5+NGzY0NNlSBmp0qcxCQgDwJmrnp2IiDdT2AFWYSci4tUUdoAzVzeoiIh4M4UdQJ7CTkTEm1XxsHPdoEJ+pmfrEBERt6raYVc8W7kjXz07ERFvVrXDztefAhOAb0GmHhwVEfFiVTvscM1WHmyzySnQYNAiIt6qyoddkV8o4SabtJwCT5ciIiJuorALiCSSTIWdiIgXq/Jh5wyKIsJkcShbYSci4q2qfNg5gqOJIkM9OxERL1blw84nJJpIo9OYIiLerErPegDgFxZLoMkhPTPb06WIiIibVPmenX9oDAD5mQc9XImIiLhLlQ87R4gr7AozUzxciYiIuEuVDzuCogAozFLPTkTEWynsisPO5CjsRES8lcIuOBoAn9xUDxciIiLuorALKg67PIWdiIi3UtgFhFFkfPDJO6SZD0REvJTCzhjyfSMId2aQnlPo6WpERMQNFHZAYWAkkSaT/Rm5ni5FRETcQGEH2MAoIslkf0aep0sRERE3UNgBPiExRJkM9qWrZyci4o0UdoB/ZC2qmTT17EREvJTCDvCLjCPWpHPgUKanSxERETdQ2AGE1QQg99AeDxciIiLuoLADCKsFgDNNYSci4o0UdnCkZ+fI2uvhQkRExB3cFnbGmJHGmNnGmPnGmJbHrGtujJlojOlbYtkLxphZxpjEksvLRXHPLiBnf7l+rYiIlA+3hJ0xphtQw1p7LnAb8GKJdfWBR4Bj7wb5ylrbA+gHPOOOuo4rOBan8SHKmcKh7Pxy/WoREXE/d/Xs+gATAKy1q4DowyustduttUOBbSU/YK1NLH6ZDhxyU12lczjIC6xGDVLZcTC7XL9aRETcz11hVx1ILvG+0Bjzt99ljAkAXgOeO876W4tPcyYmJyeXtsk/F1aTGiaV7SkKOxERb+OusEsDokq8d1prnSf6gDHmDOAD4E1r7czStrHWvmetTbDWJlSrVq3sqsX1rF11c0g9OxERL+SusJsLDAIwxrQAkk60sTEmCHgFuNVau8JNNZ2Qb0QcNR2H2KGenYiI13FX2P0A+Btj5gIvAQ8X323pf5ztWwPtgR+L78icZYyJPs627hFWk0gy2HMgpVy/VkRE3M/XHTstPmU5/JjFDx+zzZMlXi8C4txRy0mLagiAM2UrcJ5HSxERkbKlh8oPi24EQHD2DvIKizxcjIiIlCWF3WHRrp5dffax82COh4sREZGypLA7LCiKwoAoGph9bE7W7AciIt5EYVeCiWlEfcde1u/N8HQpIiJShhR2JfjENKaxz37W71PYiYh4E4VdSTGNqWEPsHXPQU9XIiIiZUhhV1J0IxxYilK26o5MEREvorArqVpTAOLZztYDWR4uRkREyorCrqRqzbEOP1o6trFuj67biYh4C4VdSb7+UL05bXy2sXJXmqerERGRMqKwO4ap1YZWju0s35Hq6VJERKSMKOyOVasdETadA3u2UFB0wlmJRESkklDYHatmGwDii7awQc/biYh4BYXdsWq2xjr8SHCsZ/lOXbcTEfEGCrtj+QdD3Y50913Lb5sPeLoaEREpAwq7UpiGPWjKVhat2UxGboGnyxERkdOksCtNo3NxYGnvXMVPK/d6uhoRETlNCrvS1O6A9Q/louA1TFqS5OlqRETkNCnsSuPjh4nvw/ksInFrMkmp2Z6uSEREToPC7nhaXkpQ4SHOdqzl26W7PF2NiIicBoXd8cT3Bv9QbopYyqQlu3A6racrEhGRf0hhdzx+QdB8AOcWzGXfgRR+XLXH0xWJiMg/pLA7kYSb8SvMZFhkIv/7ZaN6dyIilZTC7kTqJEDNNtzsP52N+zP4YaV6dyIilZHC7kSMgbNvJzx9I9dGbeB/MzZSpN6diEilo7D7O62vgPA6PBD8PZv2Z/LWr5s8XZGIiJwihd3f8fWHrncTk7KYR5vs4OXpGxi3YJunqxIRkVOgsDsZHW6EmHhuzXqXfs2ieOK71Xy3TM/eiYhUFgq7k+HrDxf+F5O6lddrTCGhfhT/mbyadA0SLSJSKSjsTlbjntBxGL4L3+Lltns4lF3Au7M3e7oqERE5CQq7U9HnGajZmvpzH2BIS1/enrWZsfO2Yq3u0BQRqcgUdqfCLxAGfQSF+fwn5wX6NY3g6e/XcPPHiWTmFXq6OhEROQ6F3amKbQKXvYvP7iW8Efg2T/Rvysx1+/VIgohIBaaw+yeaD4C+ozDrvuemzPcZ2LYWY+dvZXtKlqcrExGRUijs/qlOt0OnO2HhO4wMnQRYer48m7vGL2HT/kxPVyciIiX4erqASq3PM1CYS3jiGyzsUMAbvkMZv2gnszck8/XwLsTXCPN0hSIignp2p8fhgP4vw1m3EbHsXUb4jGPavd0I8PXhhg//YOsBndYUEakIFHanyxjo98KRU5p15j3Ch0POJKegiMvems93y3bp0QQREQ9T2JUFY+CCZ6HbA7BkHK3n3s7XN7elbnQw93y+jHu/WEZuQZGnqxQRqbJ0za6sGAPnPwHhteHHB2mQeQXfDPmCtxMzeOnnDeQXOnnruvYYYzxdqYhIlaOeXVnreDNcPQEObMBnbG/uam15tF8zflq1l/u/XM5nC7d7ukIRkSpHYecOTfvCDd9DQQ580Jth9fYwoG0cU5bvZsQ3q1i09aCnKxQRqVIUdu5SuwPcPB1CquH45BJeb76OlU9eQI3wAB6auJzrP1jI5mQ9jyciUh4Udu4U3RBumQ71O8O3txM091n+3a8pOw5mM3/TAcbO2+rpCkVEqgSFnbsFRcHgr6H9UJj7MgM3jmDtE90Z2K42k5fv1l2aIiLlQHdjlgcfPxjwP4iNh58fJ+DQTq7p9CbfLC3k6e/X0CAmmFoRQQxoG+fpSkVEvJLCrrwYA13+BdGNYNItdPzlCoY2epxxi3ZgrWt1vehg2taN9HSlIiJeR6cxy1uz/nDTVIx18tSBB1hzHcx/pCexoQH8+5uVHMrO93SFIiJeR2HnCbXawrCZENOEoEmDqb32Q0Ze3JL1ezPo9cpstuguTRGRMqWw85TwWnDjj66e3rRH6bv9v0y+42xyC5w89+M6T1cnIuJVFHae5B8CV4yDrvdC4lhazLyZe86pzi9r97FwS4qnqxMR8RoKO09zOKD3UzDwTdg2l5vX3UrbkFTe+HWTpysTEfEaCruK4szBcP23OLKT+dwxguxN81m09SCb9mew+1COp6sTEanU9OhBRdKwG9wyA/9PBzEh/1keej+Zb53n4OMwfHLTWXRpEuvpCkVEKiW39eyMMSONMbONMfONMS2PWdfcGDPRGNO3xLJAY8zNxpgp7qqpUohpjM+wGeTWTGC0/1tMbTObxjFBDP9syZFeXk6+Rl0RETkVbgk7Y0w3oIa19lzgNuDFEuvqA48Ax95f/yBggGruqKlSCY4mfNgUOHMwzTa8yzc1PiDUUcBlb/1G1xdm8vT3azxdoYhIpeKunl0fYAKAtXYVEH14hbV2u7V2KLCt5Aestc9Ya8ecaKfGmFuNMYnGmMTk5OSyr7oi8fWHi9+A3k8Tsul7fol5kWZhOdSJCuKnVXsoKHJ6ukIRkUrDXWFXHSiZRoXGmNP+Lmvte9baBGttQrVqVaADaAx0vQeu+pSg1PV86XiM57v6cCi7gGmr97J2T7qnKxQRqRTcFXZpQFSJ905rrboi/1Tzi+DGn8BZSNfZ13KB3wruGr+UC1+byycLtnm6OhGRCs9dYTcXGARgjGkBJLnpe6qOuHYwbCYmuhFv+/yXp2rOo8cZ1Xj8u9WsTErzdHUiIhWau8LuB8DfGDMXeAl42BjzgjHG303fVzWEx8FNU3E0u5Chh97i3ZjPCfaD8Yt2kLjtIGk5BZ6uUESkQjLWWk/X8I8kJCTYxMRET5fhGU4n/PIE/PY6y8N7cG3KTWQV+dKzWXXG3tDR09WJiHiMMWaxtTbh2OUaQaUycjigzzNwwfO0TZ/F+z6jaB4NM9ftZ97GA56uTkSkwlHYVWad74DL3qez7wZ+CBtFm6g87hy/hBlr93m6MhGRCkVhV9m1uRJzzec4Dm5ikv/TdAhPY/inrtFWRETERWHnDeJ7w5DJ+OUf4v3Cf9POP4kHvlzOvvRcT1cmIlIhKOy8Rd2OcONUfHz8+Mz3KYL3LKT7f39lyvLdnq5MRMTjFHbepHozuGkafhG1GB/4AjfFruHuz5cyddVeT1cmIuJRCjtvE1kXbpyKqdmKh9Ke4c7oRJ6cvJrs/EJPVyYi4jEKO28UEgNDJmManMMDWa/SLWsqHUb+wrXv/47TWTmfqxQROR0KO28VEArXfolp3JMX/d5jRPX5/LY5hR9W7vF0ZSIi5U5h5838guDq8XBGXwanvMbDUb/y4rT1mvxVRKochZ238wuEKz+B5gMYnvM+3dImM/KHNVTWYeJERP4JhV1V4OsPl4+F+At41m8seX98SvuR0/kqcaenKxMRKRcKu6rC1x+uHIezYQ9e8n+PIeFL+b+JK/j09+2erkxExO0UdlWJXyCOa8Zj6p3Nven/5a7aG3lx2nrScgoo0l2aIuLFFHZVjX+I6y7Nmq25P/VZWuctoft/f6XbCzM1H56IeC2FXVUUGA6Dv8ZR7Qw+DHiFC8O3sjc9l1enb/B0ZSIibqGwq6qCo+H6b/GLrsfzOSN5uHUW4xZsY/aGZE9XJiJS5k457Iwx4e4oRDwgtBoMnQwhMdy6/UH6xh5g+KeLWZF0yNOViYiUqZMKO2PMlOKfFwDfGmPedmtVUn7C41xDiwWE8kbhU7QL3MeNH/7B9pQsT1cmIlJmTrZnF1H880JrbU8g3k31iCdE1Ychk3E4fBjn9xw1i/bwwJfLNY6miHiNkw273caYj4Elxe/D3FSPeEpsExjyHb7OfL4Mep7d2zfy2UI9gyci3sH3JLcbCjS11q4wxvgDt7qxJvGUGi3g+q8J/vhiJoW+wMDJvgT6+XBFQl1PVyYiclpOtmd3U3HQxQHjgfpurEk8Ke5MzHUTqWkOMTH0RUZO+p0fVmimBBGp3E427K4u/vkv4P+Ae91SjVQM9c7GXP0ZdYt2Mj70NR764g827MvwdFUiIv/YyYadwxhzHlBkrd0K+LmxJqkIGp+HGfgWrQpW8Irf2zw6cZluWBGRSutkw+5BYADwsjEmEJjmvpKkwmh7FfR6igv4jb573mLi4iRPVyQi8o+cVNhZaxcCY4GeQF1r7TNurUoqjq73YM+6jWG+P7Jz6iskpWZr0GgRqXRO6m5MY8yDwDnALOBaY8wUa+1HbqxLKgpjMH2fJ3XPFu7d8SG3vBjD5siuPH5RC3q3qOHp6kRETsrJnsa8DLjUWjsauALXowhSVTh8iLr+Y3JjWvBe0Ju0cOzgzvFL2HZAo6yISOVwsmGXZ621ANZaJ+DjvpKkQvIPIeSGifgFR/CmeYFaPuk8MXk1xX8tREQqtJMNu1XGmMeMMe2MMY8C69xZlFRQ4XFwzef45KYyMeI1Fm7YxdRVez1dlYjI3zrZsLsH2AvcAqQCw91WkVRsce3gsveITV/N+2Ef8PTkVaTnatJXEanYTvZuTKe1doy19i5r7TvAf9xcl1RkzQdgej1J94K5XJs7nn+NX0pBkdPTVYmIHNc/nbz1nDKtQiqfrvfAmYP5l8/XRG76hrOe/YWvl+g5PBGpmDRTufwzxkD/V6H+Obwa+D79wrfxyNcrWb7zkG5aEZEKx5zoHyZjzALg2A0M0NxaG+nGuv5WQkKCTUxM9GQJApB9EMacjzMnncsKnmZZZiRn1ovky9s64+ej36VEpHwZYxZbaxOOXX7Cf42stZ2ttV2O+dPZ00EnFUhwNFz7JQ5bwFfho7m7a3WW7jjEz6v3eboyEZEj9Ku3nL7YeLjyE/wObeG+Q8/TIMqfj3/b5umqRESOUNhJ2Wh0LvR/BbN5Bm/GfMWibQdZvTvN01WJiAAKOylLHYZC57tomfQFQ/1nqncnIhWGwk7KVu+noUlvnnB8yK5lM1i1K013Z4qIxynspGw5fGDQBxRFNuB1n1e4/Y1veGjiCk0LJCIepbCTshcYgf/gL4kMdPB15Gv8sHgTj0xaoZnORcRjFHbiHrFNcFzxIdVzt/Jd3DgmLt7Bk1NWe7oqEamiFHbiPk3Ohz7PEn9wFh82mMm4BdtZvzfD01WJSBWksBP36jQczhxMj71judR/EaN/2cCqXWm6hici5crX0wWIlzMG+r8CBzby311vc+nqWC5atZcGMcG8ds2ZtKkT6ekKRaQKUM9O3M83AK76FJ+w6kyMeI03LqpJTkERD01cQaGmBhKRcqCwk/IRWh3HtV8S6MzholX3MrJfQ9btzeChSSs00oqIuJ3CTspPjRZwxYewbxW91z/OoDPjmLJ8N9e+v5Ds/EJPVyciXkxhJ+Urvjf0HYVZ9wMvRX/D+GGdSMsp4JuluzxdmYh4MYWdlL+zboWOt8D8/5Fw8Hta1Q5n7LytukNTRNxGYSflzxjo+wI07on5/j5GtEhhc3IWH2ngaBFxE7eFnTFmpDFmtjFmvjGm5THrmhtjJhpj+pZYdokxZq4xZqEx5ip31SUVhI8vDPoQohvTKfFerm6cz0vT1rMjJdvTlYmIF3JL2BljugE1rLXnArcBL5ZYVx94BMgssSwEeBDoBfQEHjHGBLqjNqlAgiLh2i8wGJ7JHkm0I4sHJy7nsW9XMn2NZjoXkbLjrp5dH2ACgLV2FRB9eIW1dru1diiwrcT2nYAZ1to8a20WsBBo5qbapCKJbghXj8c3fSeTYt9lydb9fPr7Dh78ajkHMvM8XZ2IeAl3hV11ILnE+0JjzIm+69jtU4CoYzcyxtxqjEk0xiQmJycfu1oqq/qd4eLXqZmykOlNJ/Ph0ASy8wsZ8c1KCvTQuYiUAXeFXRpHh5XTWnuif7WO3T6Ko8MPAGvte9baBGttQrVq1cqmUqkY2l4N3R6k4faJnJf6FQ/3bca01fsY8Po87v18KYnbDnq6QhGpxNwVdnOBQQDGmBZA0t9svwjoa4zxM8YEA62AdW6qTSqq80ZAi4Hw82PcUn09r1zZlpAAX2ZtSGbQOwuYsVbX8UTkn3FX2P0A+Btj5gIvAQ8bY14wxviXtrG19gDwETAP+BH4j7VWQ2pUNQ4HXPIOxLWDiTdzWVwqk4Z34bdHelIrIpBxC7Z7ukIRqaSMtZXzQd6EhASbmJjo6TLEHTL2wvs9AQPDZkBYTV7+eT1v/LqJ+Q/3JC4yyNMVikgFZYxZbK1NOHa5HiqXiiesJlzzOeSkwoRroCCHKzrUxVq4/oOFTFu919MVikglo7CTiqlWG7h8DOxeCt/cTr2oQP53dTsAHvxyOYey8z1bn4hUKgo7qbiaXQh9RsKab2HWcwxsV5u3rutAZn4hb8zc5OnqRKQS0UzlUrF1vgsObIA5L0JMPE3bXsXl7eswZt5WtqVk8fbgDvj56Hc2ETkxhZ1UbMbAhS/Dwa0w+S6Iqs9zl55FnaggRv+ykelr9nFh61qerlJEKjj9SiwVn68/XDkOIurC59fin76df/WMp3ZkEOMX7gDAWktlvbNYRNxPYSeVQ3A0XPslOItgwtX45Kdzdce6zNt0gG0Hshj0zgJGfLvK01WKSAWlsJPKI7YJXPUJpGyCr27kyg618HEYHv9uFYu3p/LFHztJStUUQSLyVwo7qVwadof+r8DmGdRY+Dy9m9dg7sYD+Ps4MMCYuVs9XaGIVEAKO6l8OgyFs26FBW9wb7XFAJzfvDqXta/NZwu3s2l/hocLFJGKRmEnldMFz0GDbjT9YwRPn5nBv3rG81DfZgT7+/LIpJXkFhR5ukIRqUAUdlI5+fjBleMwEXUZsu0RWvjvIzY0gKcHtiRxeyrXf7CQcQu2sWznIZxO3aUpUtUp7KTyCo6GwRPB4QufXgYZ+xjYrjavXtWWtXsyeOK71Vzy5nzdpSkiCjup5KIbwbVfQNYBGH8F5GVy6Zl1WPGfPix4tCfXnl2PCYt2aPJXkSpOYSeVX+0OcMVHsHcVfDUUigpwOAy1IoIYcWFzakUE8uyPaz1dpYh4kMJOvMMZF8BFr8CmX+D7e6F4NJWQAF9uP7cxS3ccYtnOQx4tUUQ8R2En3qPDDdD9IVj6KcwadWTx5R3qEBrgy9h5egZPpKpS2Il3Oe/f0G4wzB4FS8YBEBrgy9Ud6zJ5+W5u+ThRjyWIVEGa9UC8izEwYDRk7IEp90JoTTijDw/1bUZUiD8vTlvP54t2cEGrmkQG+RPk7+PpikWkHJjKOlJ8QkKCTUxM9HQZUlHlZcBH/eHARrjhB6jdHoAr31nA+n0ZZOcXEuzvy4j+zbkyoa6HixWRsmKMWWytTTh2uU5jincKCINrv4KQWBh/pWs+PODu8+NJyykgoX40jauF8OTk1aRk5nm4WBFxN4WdeK+wGnDdJHAWwqeXQ1YK58THMv2+7oy7+Sz+O6gtuQVFPP/TOo2nKeLlFHbi3aqdAdd8Dum7YMLVkJ9NfI0w/HwcNKkeypUJdZm4OIler8zhrvFLWLUrzdMVi4gbKOzE+9XrBJe9D0l/wNfDoKjwyKrnLm3ND3efwz3nx/PL2n1c9Po83p292YPFiog7KOykamhxMfR7AdZ9D5P/BU4nAA6HoWVcBPf1PoOFj/aid4savPzzBjbs02lNEW+isJOq4+zboMe/Yfl4+PGBI6OsHBYR7Meoy1oTGujLnZ8tIT23wEOFikhZU9hJ1XLuQ9D1HkgcC9Mf/0vgxYQG8MY1Z7L1QBZ3fLpED6CLeAmFnVQtxkCvp6DjLfDb6zDv1b9s0qVJLKMub8P8zQe4/dPFmg9PxAtoBBWpeoyBfi9CziGY8RQERULCTUdtMqhDHTJyC3hqyhp+WbuPPi1reqRUESkb6tlJ1eRwwKXvQHwf+P5+WPHlXza5vlN96scE89rMjazdk05lHW1IRBR2UpX5+MGV46DBOfDN7bB2ylGrfX0c3NGjMat2pdPvf3N5ZNJKBZ5IJaWwk6rNLwiumeAaO/OrG2Hj9KNWX9GhLuNvOZsbuzbgi8SdvDdni4cKFZHTobATCQiD6yZC9ebwxWDYOvfIKofD0KVJLE9c1IK+LWvy8vQNbD2Q5cFiReSfUNiJgOsmleu/hagGMP4q2LnoqNXGGJ4e2JIAXwfDxiXy8s/ruf2TxaTl6Fk8kcpAYSdyWEgMDPnONYD0p4Ngz/KjVlcPD+St69qTk1/E6zM3MXX1Xj6cr9nPRSoDhZ1ISWE1YchkCAyHTy6F/euOWt0tvhozHzyXP0b0ok+LGoydt1UjrYhUAgo7kWNF1nX18Bx+MO5i2LvqqNUBvj5UCwvg7vPjSc8t5KVp6z1UqIicLIWdSGliGsPQyWB84KMLYfuCv2zSqnYEN3VtyLgF2/kqcaceSxCpwBR2IsdTrSncPA1CqsEnl8D6n/6yyUN9m9K2biT/N3EFw8YlkleosTRFKiKFnciJRNaDm6a5Hkv4/DpYNv6o1YF+Pnw9vAuP9W/OL2v3c+U7C3h1+gbyC50eKlhESqOwE/k7IbEwdAo07AbfDocFbx612sdhuKVbI164vDV5hU7+N2MjD361XANIi1QgCjuRkxEQBtd+CS0GwrR/w6L3/7LJVR3rMfXe7jzUtymTl+/mo9+2lX+dIlIqhZ3IyfINgMs/gKYXwo8PwtLPSt1s+LmN6dG0Gi/9vJ6k1Gystbp5RcTDFHYip8LHDwZ9CI3Og8l3wZJxf9nEGMMzl7QC4LFvV3HvF8voO3ouq3enlXe1IlJMYSdyqvwC4erx0LgnTP6XaxLYY9SJCub/LmjKrPXJfLdsN7sP5XDVu7/rAXQRD1HYifwT/sFw9QRoeSn8/BjMeBqOOVU5pHMDereowU1dG/LRTR3JzCtk5tr9HMjMo0g3r4iUK81ULvJP+fq7ruEFRsDclyEnFS58CRw+gOsuzfeHJADgdFpqhAfw9qzNPPjVcppUD+WFy9vQtm6kBxsgUnWoZydyOhw+cNFo6HovJI6FiTdBXuZfN3MYLmhZk/X7MqgeFkB6TgG3fpJIWrZOa4qUB4WdyOkyBno/Bb1Hwprv4P2ekLrtL5td3r4OEUF+/O+aM3n3+gRSMvN5eNIKkjPy+HbpLgqL9CC6iLuYynpLdEJCgk1MTPR0GSJH2zILvhzqekzhuq+gVtujVltrMcYAMGbuFp75YS2Bfg5yC5wMaBvHgYw8ru9cnwtb1/JA8SKVnzFmsbU24djl6tmJlKVGPVzDizn84MP+rvAr4XDQAdzSrRH39oqnUWwol7evw5Tlu1mwJYX35mwp35pFqgD17ETcIX23awLYAxvg0neg9aATbu50Wmau28/iHam8PWszcx86j7rRweVUrIj3UM9OpDyFx8GNP0Lds2HSzaU+i1eSw2Ho1aIG13SsB8BXi5M06opIGVLYibhLUCQMngQtLnE9i/fjQ1CYd8KP1IsJplOjaF6bsZGLXp9HSmYeBzJP/BkR+XtuCztjzEhjzGxjzHxjTMsSy0ONMROMMXOMMd8aY8KLl19ljJlrjEk0xlzvrrpEypVfoGt4sU53wKJ34Z1usG/NCT/ywdCOjLqsNZv2Z3LOC7+S8MwvzN6QXE4Fi3gnt4SdMaYbUMNaey5wG/BiidX3AVOstd2B6cBwY0wUcCdwPtAduO9wCIpUeg4H9H0erpsIuYdgTC/XIwrHERLgy9Vn1WPM0ATOahhNZLAfny/awW+bD7BxX0b51S3iRdzVs+sDTACw1q4Cokus6wl8Vfx6EtAZaAIstdbmW2uzgd+B5m6qTcQz4nvDrbNdE8F+OQRmjATn8Wc27xZfjY9vOovL29dh+pp9XP/BIoaMXURmXmE5Fi3iHdwVdtWBkuddCo0xh78rwFp7eNiIFCAK2Ax0NsaEG2NCgbMpZSgzY8ytxac5E5OTdVpHKqHwWq4bV868Hua+BBOugZxDJ/zI5e3rUOi01AwPZG96Lq9O31A+tYp4EXeFXRquEDvMaa09PDyEs0TwRQHJ1tqDwDPA98D7wFZg27E7tda+Z61NsNYmVKtWzU2li7iZbwBc/Dr0fxk2z4D3z4OkxcfdvEVcOG9f156JwztzZYe6fPL7dvZn5LJhX4bu2BQ5Se4Ku7nAIABjTAsgqcS6hcDA4teXA78AWGsnF1/HexhXOO5yU20inmcMdLwFhn4PhfnwQW+Y/SIUlX6Ksl/rWtSKCOLWcxuRX+jkincW0OfVObz08/pyLlykcnLLQ+XFPbc3gVZABq6bVO4CHgfCgU+AIGATcKe1Ns8YMx6oV7z9ndbaEw4joYfKxWvkHIIfHoBVE6F2gush9Nj4425+80d/MGPdfhrEBLMtJZtmNcPo3DiGdnUjqRMVTICvgyU7UqkZHkj3M6oR6OdTfm0R8bDjPVSuEVREKoqVE+HHB6EgB85/As4e7rqT8xg7UrL5ec1ehnRuwLgF2/h1/X4St6WSV/jXgaSHdWvIiP4tyqN6kQpBYSdSGWTshSn3wIapUK8LXPImRDf624/lFRaxIyWbpNQc0nIKaF8vin9/s5KdqdnMerDHUWNyingzDRcmUhmE1YRrPoeBb8G+VfBWF5j677+9YzPA14f4GmGc16w6l5xZm3oxwfRtVZPtKdn8snY/czfq7mWp2hR2IhWNMXDmdXDHAmh5CSx8B97uClvnnNJuejarDsCwcYkMGbuIhVtSjqxbvD2VbQeyyrJqkQpNYSdSUUXUcd2scvN01+MKH18M00ZAQe5JfTwuMogz60USFxFIvehg7v58KV8vSeK1GRsZ9M5vXPXeAlI07qZUEbpmJ1IZ5GfBz49D4gcQ2xQuegUanPO3H0vLKcDPx7D1QBb/Gr+ULcW9ua5NYvhjWyqdGsXw0Q0dcTh0TU+8g25QEfEGG3+BH+6DQzugzdVw3qMQ1eCkPlrktCzbeYjwQF+aVA9l/KIdjPhmFff1OoO7z2+im1jEKyjsRLxFfjbMfRl+e801tmbHm+G8f0NQ1N9/tgRrLfd+sYzvlu2mUWwI6bkFdIt3PZdXPyaY289t7KYGiLiPwk7E26TvdoVe4ljwC4EzB7tubKnZ+qR3kV/o5IvEnfy8ei+Rwf5MX7OXIqeloMjySL9mnFk3krMaRqvXJ5WGwk7EW+1dBfNehbWToSgfGveE1ldAq0Hg639Ku8rJd83CMPTDRSzaehCAxy9qwc3nNCzzskXcQWEn4u1yUiHxQ/hjDKTvgrqd4PIxEFn3lHeVW1DE8p2H+GDeVmas28+958fTIi6csEA/fBywJy2X/q1rAajXJxWKwk6kqrDWNfTY5H+BswBaXgpd7zml05uHZeQWcP+Xy5m+Zt9f1l3RoQ5zNx7gX+c34bqz65dF5SKnTWEnUtWkboeF78KScVCYAxc875ppoZTxNv/OluRM0nMLOZiVR16Bk6mr9/Ldst0YA2EBvsx56Dwig/3Zk5bDR79t4/bujYkKObVTqCJlQWEnUlXlpMLXt8HGaVCzDfR/Bep2PK1d5hYUMWX5bhrEhnDluwu4uG0cj1/Ugus/WMTaPel0i48lI7eQ9vWiePyi5jrVKeVGYSdSlTmdsPIrmPGU6y7O+N7Q9mpoPhB8fE9r16/N2MgrxbOnOwxc1CaOyct3E+DrIK/Qye3nNuaRfs3KohUif+t4YXd6f8tFpHJwOKDtVdC0H8x7BVZOgok3QURdOPs2aD8EAiP+0a7vPj+eJtVDWbUrjf5tatG8Zjjdz6hG58YxvD5jI+/O2Uy/VjUJCfDhvi+W8+TFLelQ/9SeCRQ5XerZiVRFTqfrtOaCN2HbXNdzeo16QHwvaNILIuuVydek5xZw/suzCQvwxQJbD2Rx7hnV+Pims8pk/yLH0hQ/IvInh8PVy7vhe7h1tuuU5t6V8P19MLo1jOkNm3+FwvzT+prwQD9evqIthU5LUmo25zerzuwNyaxMSqOy/qItlZN6diLiYi0c2Phnjy9jD/gFQ/OLod210KDbP7qT07VrS05BEdn5RXR74VdyCoq4umNdhnZpwNh5W7npnIbc8/lSsvKKuOO8xlx3dn0Ki5wsT0qjfb1I3eAiJ003qIjIycvPgk0zYPMMWPUN5KW5ru+1vBTi+0C9TuDj9492vWl/Jm/M3Mh3y3fTpFooG/dn4uMwBPo6aFI9lLV7M/jlvnP5eME2Ppi3lTeuPZOL2sQxZu4W0nIKeKBP0zJurHgThZ2I/DMFObDuB1g23jWBrLMA/EOh7tlQvzM07Q81WpzSLlMy8+gyaiZ5hU76tarJvE0HGHVZGzrUj+K8l2YRFezH7rRcjIGE+lE8flELBr45H2th9FXtuOTM2m5qrFR2CjsROX15GbBlNmz5Fbb/BvvXuJbXaAVtroSWl5308GTP/7iW6Wv38dM93fBzOI7MqffDij1MWLSD+jHBxEUG8eK09VQLC8AAtaOC2LQ/k3kP9SQi+J/1LMW7KexEpOxlJsPqb2Dll5D0h2tZeB1X8LUY6ArB4zzHZ63FWk44cWxadgFXv/87MSH+3NMrntAAX/r9by53nx/P/b3PYOuBLGpFBLJ0xyFW707jlm6N3NFKqUQUdiLiXimbYePPrp7fxmlgnWB8oFZbaD3INTB1zVbgG3BaXzP808XM2ZBMhwbRzNmQTP82tVizO52tB7KY9WAPGsSGlFGDpDJS2IlI+cnc7wq9/Wtg43TYt9K13MffNWRZnQSonQANukJ43CntentKFv/+ZiU7DmZTIyyQxO2pR9ZdmVCHGuGBXN6+Dp/+vp3WdSIY2K42+9NzeWvWZv7VswkxoacXtlKxKexExHPSdsGuRNepzqTFsHupa3Bq43DNvxde2zUrQ52OUJjrCsXa7f92t1l5hfR4aRZhAb40qhbCL2v3A65hy5wWGsQE8+uDPXh40gq+TEziqoS6vDCojbtbKx6k4cJExHMiarv+tBjoel9UCPtXw6pJsH6qK/yWfHz0Z2onuB51qNkKohu7AvGY5/xCAnz54tZO+Pk4SMspAAxXd6zLh79txdfhYPaGZH5Zu59JS3YRE+LPl4t3cl2nerSpE/mXEudtPMDKXWl0ahTNmfU0nJm3Uc9ORDzPWji0w9X78w2EtCRY/NGfd3sC+ARAdENX8MU0Kv7Z2NULDI51vS7x8PmuQzl0HTWTAF8Hfj4OpvzrHK5+bwHB/r483Lcp1cICj4zR+dPKPQz/bAkA8dVD+fm+7qTlFBAZrGmKKhudxhSRyid9t2tUl4ObXTfAHNzi+pm6FYqOGcosKBrqnuU6FVqnI/gFc8dX65i7P5Bnr+nKxW3j+H1LCte+/ztOC8H+Pky8vQu/rN3HW7M20bxWOD2bVufl6Ru4/dzGjJ23lW/u7ELLuBMPkL3rUA75hU4a6saYCkFhJyLew1kE6btc4ecsdF0TTFoEOxfBgQ1/3T6kmuvaYFgt9u5NIs0/jlfWhpKTX4QDS7t60QzpfRbp/jXo8eYywNVDbFc3kq+Hdznq8YisvEImLNrB4E71yS9y0ueVOeQVFvHrgz3UE6wAFHYiUjVkH3RdA7RO10PwaUmwdwVsnQvZB1w9wKxkoPR/+3abGswoaE1wzXjG7apFw7jqXNjQhzbN4qnZuB2vTN/A+JmLeaJHNAvTY5iw1HVTzHVn12fkJa1wFuSx5UAmtWMiCfL3KceGCyjsRET+lLEXUrcXX+MzrmDM2AOHdrA98UdiU5cTQvZfPpYbEMv23BCamu0AZNkAMkIakOcIZEsaxEf5UDN9Gb44OWgiCYmuRUB4Ndcg2g3Pdd1hai0c2u666zS8tmuwbb9AyMvknfk7SM0zPNqvuesmnpxUCIk96lqknJjCTkTkVKTvgaRFOIuK2JUfxOc/z+OM7CXUNAfJqt+LbzZDr5AtXNTACfmZbN21l5z8QtYEtKNx3Th2bV1LTb8czo7Oxu5dicFifYMwRflgi0p8kYHYM+DgFgqdTg7ZUGICijD5WYB1BWJ8H4hpAgGhULsD5KbBoZ2wYaprWb0url1F1HH9yU2D0Oqu1+AK2JxU16Me2SmugA2KhKwDrm2cha4BADL3ucY+jazn+kzKJte66EZ/HQwgM9n1C0JwjOtOW2eR6xRyUT7ENnUFuAfo0QMRkVMRXgtaDMQB1AXuaNWbJTtSsT4OutWP4o/pG2jWrjY+NcNcm2fk8vPiJK47uz4RQX78NmMj9/6ygV9v7cGoSb9hts+lt/8WYmKiITaehMY1OLQ/iVnLNjAgYDd+7Xvy4e+7iCSTvs0aEx0ZRb5fKP67FsGKL6Eg6681hlSHgmxY+mnpbfAJAIePK4iK8o5ZaQDrmqE+N90VhIdDOKKuq7ebvuvP76neHNJ2uvZVmOsKxsMCI1zL8zP/fF/nLFev1C/YVWNYTSgqcK0LjHDdfZu8zhWqxgEtLob2Q/7hwfp76tmJiLjBql1pXPT6PGpHBrE3PZfbujfi26W7yMgtJCOvkOphAUSH+LNubwY1wwO5v88ZPDRxBQAjL2lFUmo2783ZwmtXn8mAlrGuwMjc7xqNJjgGQmtATLyrJ5Wxx3Wq89BOV0AFhLuuVabvcoWWwwdCa7rCLCjadS3z8CnSfatdvUBnoWu/GNi9xPW5Bt3APwRWfe36jpjG4PADh68r/CLruk4JH9jo+v7aHVw9wA3TXEGWdcA1XZRfsOvzPv6uwQTAFcTVm7n2Z52u8VQ7DT/t/+46jSkiUo6stXR6fgb70vO4sWsD/jOg5ZF1S3ekcvPHiRzMymd4j8Z8MG8rDgP5hU5CA3wpclqy8osI9vchvnoo3911DgA5+UVsTs6kZVw4Y+dvo2ez6pXnkQen0zUoQH6Wa9qowMjjDhJ+OnQaU0SkHBlj6NeqFt+v2M29559x1Loz60Xxxa2dmLfpADd0aYC18M7szTSrGUZcZBAz1+3nyoQ6tIyL4D+TVzNxcRIxIf68OG09a/ak8+a17Rn5/Ro27c/g+ctcw5+l5xbw/pwthAT4clVCXaJCKthjEIdHv/EPcf0pZ+rZiYi4SX6hk5yCIiKCTjz3XkZuAb1emU3/1nE0rxXGR79tY8KtnTBAl1EzycgtBCA0wJes/EJiQwNIzsgjLiKQ+Y/0xBjDiG9W8tnCHYBrwtsJxcOonYyM3AJC/H1PON1SZaHTmCIiFVhGbgEBvj74+x4dUHvTctmekoWvj6FxtVCGjUvkj22pGOO6t+Ot69qzZnc6b87axA1dGtCubiT3fL6Me3vFc2+vP3uUadkFhAf5Yo55jCEpNZu+o+dyx3mNuaNHk3JpqzvpNKaISAUWFlh6769mRCA1I/68jb9vq1r8sS2VKzvU5YvEndzx2RKMgTZ1Irmv9xmEB/oxZfkePv19O9XDAvl6SRIXt4vjycmreeu69lQPD2TB5hQaVwulb6uaPP/jOjLzCvl0wXZu694YHy/o3ZVGYSciUokMbBfH3I3J3NWzCZuSM8ktKGLsDR2pEf5nIF57dl1+WbuPEd+uxFqOzPn385p9LNxykF2HcvB1GN64tj0/rNxD+3qRLNlxiDkbkzmvaXXAdQ3wvs+XcUVCHfq2qkVadgG5hUVHfU9lotOYIiKVVF5hEf4+jr+cmiwscnLOC79yMCufV69qx5wNySQdyiZxWyp5hU7uPK8xb/66mQBfB8H+Psx68Dx6vjyLTo1iePM61zyCz/24lvfmbMHHYYivHsr6fRmE+Pvy26M9CT9OL7QiON5pzJO7eikiIhVOgK/PX4IOwNfHwX8HtWH01e3o36YWLwxqw0Vt4sgrdOIwcPM5jegWH0teoZMbuzYkItiPPi1rMHtDMvvTcxn10zo+nL+Vi9vGcWHrWlQLC2Bo5wZk5hUyednuo75r3sYD/LBiDwAFRU7u+2IZC7eklEv7T4VOY4qIeKHuZ1Q76v05TWIBOLthDNEh/tx1XhOy84sY2rkBAOc3q8GERTu54t0FJKXmcE6TWP4zoAUxoa5hwqy1/L4lhS8Td3JVx7r4+Th44rtVjFuwHWOgac1zWbT1IN8sdY26cnajmPJr7ElQz05EpAqoGx3MTV0bMrxHY8AVRpOGdyEi2HVKsmuTWAJ8HWxPyeaOHo35+KazjgQduJ4bvLpjXVYkpdH6yWl8lbiTzxbuYEDbOIL8fHj2hzW8NmMjAIu2HgRcj15s2JdRzi0tnXp2IiJVxBMDWhx3XZC/D93PqMYf2w4yrHujUrcZ0rkBUSH+/O+XjTw0aQXWwv29zyAuIpB352whwNfBgLZxTFm+m50Hs3n2h7VMXb2X/q1r8cpVbQnwPXrKo8IiJ8uT0piwaAfd4mMZ2K52mba3JIWdiIgA8MLlbcjMLTzuDSgOh2Fgu9qEB/lx44d/0KlRNA1jQ7iv9xmc3SiaDvWj2X0ohynLd3PXhKUs33mIbvGx/LByDxe2rkX/NrWO7Ov7Fbt5ZNJKMvMKCfb3oWmNMLe2TWEnIiIARIf4E30Sw4yd17Q6j/VvzlkNowEI9POhZ7MaAIQF+BIZ7MfynYe47ux6PHlxS9o+9TMLt6bQunYEz/24lo37M9iWkk3bOhEM7dKAns2qH/c5w7KisBMRkVN2S7fST3U6HIaXr2gLwPnNXQHYoX4Uczce4KdVe8nKK6Rrk1gS6kfzxIAWhASUTwwp7EREpEwdDrnDOjWK4cVp6wH48rbOR3qE5Ul3Y4qIiFt1Kn4MoUvjGI8EHahnJyIibta2TgTXnV2PwZ3qe6wGhZ2IiLiVr4+DZy9t7dEadBpTRES8nsJORES8ntvCzhgz0hgz2xgz3xjTssTyUGPMBGPMHGPMt8aY8OLl5xlj/jDGLDTGXO+uukREpOpxS9gZY7oBNay15wK3AS+WWH0fMMVa2x2YDgwvXv4C0As4B3jQlDaUt4iIyD/grp5dH2ACgLV2FVDyXtOewFfFrycBnYtfHwQigFAg01bWifZERKTCcVfYVQeSS7wvNMYc/q4Aa21B8esUIKr49StAIrAKGFvaTo0xtxpjEo0xicnJyaVtIiIi8hfuCrs0/gwxAKe11nn4dYngiwKSjTHVgXuA+sV/ehpj2hy7U2vte9baBGttQrVq1Y5dLSIiUip3hd1cYBCAMaYFkFRi3UJgYPHry4FfgFig0FqbY60tBFKBOm6qTUREqhh3hd0PgL8xZi7wEvCwMeYFY4w/8DxwqzFmFtAB+NBauwZINMb8ZoyZDxhgqptqExGRKsZU1vtAEhISbGJioqfLEBGRCsQYs9ham3Dscj1ULiIiXk9hJyIiXk9hJyIiXq/SXrMzxiQD209zN7HAgTIopzJQW71XVWqv2uq9yqq99a21f3k2rdKGXVkwxiSWdiHTG6mt3qsqtVdt9V7ubq9OY4qIiNdT2ImIiNer6mH3nqcLKEdqq/eqSu1VW72XW9tbpa/ZiYhI1VDVe3YiIlIFVMmwO94s6t7EGLPHGDOr+M+1xpimxpgZxW1+8e/3ULEZY6oZY541xowsfl9q+7zhWJfS1nuNMWuLj+3PJbbzhrZGGmM+L27bHGNMQy8/tqW11yuPrzHG3xgzpbhds40xtcvz2PqWxU4qk5KzqBtjWuGaRf1CD5flDpustT0OvzHG/ATcbK3dZoz5yhhztrV2oefKO20vA5uA4OL3ozmmfYA/3nGsj20rwGPW2kmH33jR3+tg4H5r7W5jTH/gQaAR3ntsS2vvRrzz+BYCV1lrs40xg4GhQDfK6dhWxZ7diWZR9yaph18YY/yAQGvttuJFJWeIr5SstUOAOXDC9nnFsS7Z1hJSj3nvLW3dba3dXfw2FcjHu4/tse3NKvG6pErfXmut01qbXfw2HlhJOR7bqhh2J5pF3ZvUKz4N8BUQh2tW+MNKzhDvDWIpvX3eeqxzgOeMMXONMbcXL/OqthpjauPq5bxEFTi2Jdo7Gi8+vsaY/zPGbAQSgCWU47GtcqcxOfEs6l7DWtsOwBhzHq5/MCJLrI7i6L9MlV0apbcvCC881tbad4F3jTGBwLfGNW+k1/y9NsZcBAwAhuH6hz+yxGqvO7Yl22utTQG89vhaa18EXjTG9ANepRyPbaX7zaAMnGgWda9gjPEp8TYVsEBA8W+PAJfhmiHeKxSfGimtfV55rI0xh39JzQOycR1fr2irMaYNMMBae5u1NsXbj+2x7S1e5pXH1xgTZowxxW934Mqfcju2VbFn9wNwYfFvSxnAbR6uxx3qGWM+w/U/Sz4wHIgBJhpj8oDJ1tp1nizQDe7nmPYZYzbgncf6KWPMOYAf8LW1do0xZh3e0da+QDdjzKzi9zvw7mNbWnt3eunxbQaMLj6OOcBduC5BlMux1UPlIiLi9ariaUwREaliFHYiIuL1FHYiIuL1FHYiIuL1FHYiIuL1FHYiFYAxJt38OXD3/5XRPhsYYz4vi32JVHZV8Tk7kYpoTcmBu0WkbKlnJ1JBGWN+N66pfWYVj5PYsHj5xcXvZxljvjPGxBQvP794PNTZxpgHincTZoz51BizxBjzv+LtOhlj5hXv404PNU+kXOmhcpEKwBiTjmtgXIBXrLWTjTFbgMustcuMMT1wTYlyH/ATcH7xVClXAJ2AJ3ENtdTHWptWPHBuPWAm0BrXsFNLgR7Af4DvrbUzjDGOyjjGosipUs9OpGJYY63tUfxncvGyZGvtsuLXC3GFVzzwR4mpUn7BNQxTU2ChtTYNXNOpFK9PtNZmWddvtetxDbz7DNDTGPMCUMvN7RKpEBR2IhVXjDGmUfHr/sAyYAtwljEmqHh5T1w9tu1Ap8PLi+f4AyjZazt8GifbWjsC1+j6r7mvfJGKQzeoiFQMLUoMBrzGWnsHcBC4xxjTGsgEbrDWHjTGvAz8aozJxjUi/B3W2kxjzGhgtjEmE/gCmHac73rQGHMBrpmjR7utRSIViK7ZiVRQxpjfrbWdPF2HiDfQaUwREfF66tmJiIjXU89ORES8nsJORES8nsJORES8nsJORES8nsJORES8nsJORES83v8Dd1dgT3P4cPUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(range(1, N_EPOCHS+1), hist.history['loss'], label='Train Loss')\n",
    "plt.plot(range(1, N_EPOCHS+1), hist.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss', fontsize=20)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1811,
   "id": "4593789b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T06:47:55.385302Z",
     "start_time": "2022-07-21T06:47:55.323291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.7348\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a58ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
